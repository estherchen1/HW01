{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Copy of ps2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/estherchen1/HW01/blob/master/Copy_of_ps2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "nSYV3U4JZdzt"
      },
      "source": [
        "## Goals\n",
        "\n",
        "The goals of the coding part of this homework assignment are to:\n",
        " * Practice specifying and fitting linear regression and multinomial regression models in Keras\n",
        " * See how you can do the calculations to generate predictions from these models directly in numpy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "qO0Kphe9bPJk"
      },
      "source": [
        "## Module Imports\n",
        "Please add code below to import numpy and any keras submodules you need.  Set a seed for random number generation from numpy before importing keras.  I've already imported pandas, a function to get train/test splits, and a softmax function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1FzuhTFCZHoY",
        "outputId": "3f543297-d7a7-4553-b889-cced83eb92f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        }
      },
      "source": [
        "import pandas as pd\n",
        "from scipy.special import softmax\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import numpy as np\n",
        "np.random.seed(38439784)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from keras import models\n",
        "from keras import Sequential\n",
        "from keras import layers\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Ht1fJQimoAZT"
      },
      "source": [
        "## Problem 1: House sale price prediction\n",
        "We have a data set with a number of characteristics of houses sold in the city of Ames, IA, as well as the sale price of the house.  Let's fit a model to predict sales price of a house.  (Original data source: De Cock, D. (2011). Journal of Statistics Education, Volume 19, Number 3.)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Mox46aAzn_jj",
        "outputId": "85448555-8b49-4f1b-cad3-878c4f0bec7d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 581
        }
      },
      "source": [
        "# read in data\n",
        "house_prices = pd.read_csv(\"http://www.evanlray.com/data/AmesHousing/AmesHousing.csv\")\n",
        "house_prices = house_prices[['Overall_Qual', 'Overall_Cond', 'Lot_Area',\n",
        "  'Bldg_Type', 'Street', 'Total_Bsmt_SF', 'Heating_QC', 'Gr_Liv_Area',\n",
        "  'Bsmt_Full_Bath', 'Fireplaces', 'Garage_Cars', 'Garage_Area', 'Wood_Deck_SF',\n",
        "  'Year_Built', 'Year_Remod_Add', 'Sale_Price']]\n",
        "house_prices = pd.get_dummies(house_prices, drop_first = True)\n",
        "\n",
        "# how much data do we have?\n",
        "print(\"shape of house_prices = \" + str(house_prices.shape))\n",
        "print(house_prices)\n",
        "\n",
        "house_prices.describe(include = 'all')\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "shape of house_prices = (2930, 37)\n",
            "      Lot_Area  Total_Bsmt_SF  ...  Heating_QC_Poor  Heating_QC_Typical\n",
            "0        31770           1080  ...                0                   0\n",
            "1        11622            882  ...                0                   1\n",
            "2        14267           1329  ...                0                   1\n",
            "3        11160           2110  ...                0                   0\n",
            "4        13830            928  ...                0                   0\n",
            "...        ...            ...  ...              ...                 ...\n",
            "2925      7937           1003  ...                0                   1\n",
            "2926      8885            864  ...                0                   1\n",
            "2927     10441            912  ...                0                   1\n",
            "2928     10010           1389  ...                0                   0\n",
            "2929      9627            996  ...                0                   0\n",
            "\n",
            "[2930 rows x 37 columns]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Lot_Area</th>\n",
              "      <th>Total_Bsmt_SF</th>\n",
              "      <th>Gr_Liv_Area</th>\n",
              "      <th>Bsmt_Full_Bath</th>\n",
              "      <th>Fireplaces</th>\n",
              "      <th>Garage_Cars</th>\n",
              "      <th>Garage_Area</th>\n",
              "      <th>Wood_Deck_SF</th>\n",
              "      <th>Year_Built</th>\n",
              "      <th>Year_Remod_Add</th>\n",
              "      <th>Sale_Price</th>\n",
              "      <th>Overall_Qual_Average</th>\n",
              "      <th>Overall_Qual_Below_Average</th>\n",
              "      <th>Overall_Qual_Excellent</th>\n",
              "      <th>Overall_Qual_Fair</th>\n",
              "      <th>Overall_Qual_Good</th>\n",
              "      <th>Overall_Qual_Poor</th>\n",
              "      <th>Overall_Qual_Very_Excellent</th>\n",
              "      <th>Overall_Qual_Very_Good</th>\n",
              "      <th>Overall_Qual_Very_Poor</th>\n",
              "      <th>Overall_Cond_Average</th>\n",
              "      <th>Overall_Cond_Below_Average</th>\n",
              "      <th>Overall_Cond_Excellent</th>\n",
              "      <th>Overall_Cond_Fair</th>\n",
              "      <th>Overall_Cond_Good</th>\n",
              "      <th>Overall_Cond_Poor</th>\n",
              "      <th>Overall_Cond_Very_Good</th>\n",
              "      <th>Overall_Cond_Very_Poor</th>\n",
              "      <th>Bldg_Type_OneFam</th>\n",
              "      <th>Bldg_Type_Twnhs</th>\n",
              "      <th>Bldg_Type_TwnhsE</th>\n",
              "      <th>Bldg_Type_TwoFmCon</th>\n",
              "      <th>Street_Pave</th>\n",
              "      <th>Heating_QC_Fair</th>\n",
              "      <th>Heating_QC_Good</th>\n",
              "      <th>Heating_QC_Poor</th>\n",
              "      <th>Heating_QC_Typical</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>2930.000000</td>\n",
              "      <td>2930.000000</td>\n",
              "      <td>2930.000000</td>\n",
              "      <td>2930.000000</td>\n",
              "      <td>2930.000000</td>\n",
              "      <td>2930.000000</td>\n",
              "      <td>2930.000000</td>\n",
              "      <td>2930.000000</td>\n",
              "      <td>2930.000000</td>\n",
              "      <td>2930.000000</td>\n",
              "      <td>2930.000000</td>\n",
              "      <td>2930.000000</td>\n",
              "      <td>2930.000000</td>\n",
              "      <td>2930.000000</td>\n",
              "      <td>2930.000000</td>\n",
              "      <td>2930.000000</td>\n",
              "      <td>2930.000000</td>\n",
              "      <td>2930.000000</td>\n",
              "      <td>2930.000000</td>\n",
              "      <td>2930.000000</td>\n",
              "      <td>2930.000000</td>\n",
              "      <td>2930.000000</td>\n",
              "      <td>2930.000000</td>\n",
              "      <td>2930.000000</td>\n",
              "      <td>2930.000000</td>\n",
              "      <td>2930.000000</td>\n",
              "      <td>2930.000000</td>\n",
              "      <td>2930.000000</td>\n",
              "      <td>2930.000000</td>\n",
              "      <td>2930.000000</td>\n",
              "      <td>2930.000000</td>\n",
              "      <td>2930.000000</td>\n",
              "      <td>2930.000000</td>\n",
              "      <td>2930.000000</td>\n",
              "      <td>2930.000000</td>\n",
              "      <td>2930.000000</td>\n",
              "      <td>2930.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>10147.921843</td>\n",
              "      <td>1051.255631</td>\n",
              "      <td>1499.690444</td>\n",
              "      <td>0.431058</td>\n",
              "      <td>0.599317</td>\n",
              "      <td>1.766212</td>\n",
              "      <td>472.658362</td>\n",
              "      <td>93.751877</td>\n",
              "      <td>1971.356314</td>\n",
              "      <td>1984.266553</td>\n",
              "      <td>180796.060068</td>\n",
              "      <td>0.281570</td>\n",
              "      <td>0.077133</td>\n",
              "      <td>0.036519</td>\n",
              "      <td>0.013652</td>\n",
              "      <td>0.205461</td>\n",
              "      <td>0.004437</td>\n",
              "      <td>0.010580</td>\n",
              "      <td>0.119454</td>\n",
              "      <td>0.001365</td>\n",
              "      <td>0.564505</td>\n",
              "      <td>0.034471</td>\n",
              "      <td>0.013993</td>\n",
              "      <td>0.017065</td>\n",
              "      <td>0.133106</td>\n",
              "      <td>0.003413</td>\n",
              "      <td>0.049147</td>\n",
              "      <td>0.002389</td>\n",
              "      <td>0.827645</td>\n",
              "      <td>0.034471</td>\n",
              "      <td>0.079522</td>\n",
              "      <td>0.021160</td>\n",
              "      <td>0.995904</td>\n",
              "      <td>0.031399</td>\n",
              "      <td>0.162457</td>\n",
              "      <td>0.001024</td>\n",
              "      <td>0.294881</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>7880.017759</td>\n",
              "      <td>440.968018</td>\n",
              "      <td>505.508887</td>\n",
              "      <td>0.524762</td>\n",
              "      <td>0.647921</td>\n",
              "      <td>0.761137</td>\n",
              "      <td>215.187196</td>\n",
              "      <td>126.361562</td>\n",
              "      <td>30.245361</td>\n",
              "      <td>20.860286</td>\n",
              "      <td>79886.692357</td>\n",
              "      <td>0.449842</td>\n",
              "      <td>0.266848</td>\n",
              "      <td>0.187609</td>\n",
              "      <td>0.116061</td>\n",
              "      <td>0.404107</td>\n",
              "      <td>0.066473</td>\n",
              "      <td>0.102332</td>\n",
              "      <td>0.324377</td>\n",
              "      <td>0.036930</td>\n",
              "      <td>0.495906</td>\n",
              "      <td>0.182467</td>\n",
              "      <td>0.117482</td>\n",
              "      <td>0.129535</td>\n",
              "      <td>0.339747</td>\n",
              "      <td>0.058331</td>\n",
              "      <td>0.216211</td>\n",
              "      <td>0.048828</td>\n",
              "      <td>0.377753</td>\n",
              "      <td>0.182467</td>\n",
              "      <td>0.270598</td>\n",
              "      <td>0.143943</td>\n",
              "      <td>0.063876</td>\n",
              "      <td>0.174424</td>\n",
              "      <td>0.368933</td>\n",
              "      <td>0.031987</td>\n",
              "      <td>0.456067</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1300.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>334.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1872.000000</td>\n",
              "      <td>1950.000000</td>\n",
              "      <td>12789.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>7440.250000</td>\n",
              "      <td>793.000000</td>\n",
              "      <td>1126.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>320.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1954.000000</td>\n",
              "      <td>1965.000000</td>\n",
              "      <td>129500.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>9436.500000</td>\n",
              "      <td>990.000000</td>\n",
              "      <td>1442.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>480.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1973.000000</td>\n",
              "      <td>1993.000000</td>\n",
              "      <td>160000.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>11555.250000</td>\n",
              "      <td>1301.500000</td>\n",
              "      <td>1742.750000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>576.000000</td>\n",
              "      <td>168.000000</td>\n",
              "      <td>2001.000000</td>\n",
              "      <td>2004.000000</td>\n",
              "      <td>213500.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>215245.000000</td>\n",
              "      <td>6110.000000</td>\n",
              "      <td>5642.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>1488.000000</td>\n",
              "      <td>1424.000000</td>\n",
              "      <td>2010.000000</td>\n",
              "      <td>2010.000000</td>\n",
              "      <td>755000.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            Lot_Area  Total_Bsmt_SF  ...  Heating_QC_Poor  Heating_QC_Typical\n",
              "count    2930.000000    2930.000000  ...      2930.000000         2930.000000\n",
              "mean    10147.921843    1051.255631  ...         0.001024            0.294881\n",
              "std      7880.017759     440.968018  ...         0.031987            0.456067\n",
              "min      1300.000000       0.000000  ...         0.000000            0.000000\n",
              "25%      7440.250000     793.000000  ...         0.000000            0.000000\n",
              "50%      9436.500000     990.000000  ...         0.000000            0.000000\n",
              "75%     11555.250000    1301.500000  ...         0.000000            1.000000\n",
              "max    215245.000000    6110.000000  ...         1.000000            1.000000\n",
              "\n",
              "[8 rows x 37 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "r3T6yBVx5qYB",
        "outputId": "c8e54790-ed35-4552-f1af-fab2b3a96f53",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "X = house_prices.drop(['Sale_Price'], axis=1).to_numpy()\n",
        "y = house_prices['Sale_Price'].to_numpy().reshape((house_prices.shape[0], 1))\n",
        "\n",
        "print(X.shape)\n",
        "print(y.shape)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2930, 36)\n",
            "(2930, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0B6Z_YDHp_oc",
        "outputId": "0e0363de-9609-4040-8f3b-79230c2a257f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size = 0.2, random_state=42)\n",
        "\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(X_val.shape)\n",
        "\n",
        "\n",
        "print(y_test.shape)\n",
        "print(y_train.shape)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1875, 36)\n",
            "(586, 36)\n",
            "(469, 36)\n",
            "(586, 1)\n",
            "(1875, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "pVwwMAlE7o6N"
      },
      "source": [
        "#### (a) Define an appropriate model in Keras.  Use Adam ('adam') for your optimizer and no additional metrics of performance other than your loss function.  Run the estimation process for about 1000 epochs using a batch size equal to the number of examples in your training set (this will take about a minute).  We'll see what these things mean starting next week.\n",
        "Things to consider:\n",
        "\n",
        "* How many units do you need in your output layer?\n",
        "* What activation function do you want to use?\n",
        "* How many inputs (features) will your network use?\n",
        "* What is the appropriate loss function to use?\n",
        "\n",
        "**Note: the only scenario where you'd use a method like this to fit a basic linear model is if your training set was too large to use other methods.  For a basic regression model there are much faster approaches to parameter estimation based on direct matrix manipulations.**  We're doing this to get practice setting up models in Keras and working with the results.  You'll likely see that when the estimation process stops the loss function is still decreasing, indicating that you have not yet reached a minimum of the negative log-likelihood.  If we really wanted the best-performing model, we'd let estimation keep running.  You can do that if you want to, but there's no need to for the purpose of this assignment.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZtlNGkJ270jU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a40d7bcb-db81-4b9c-c9e4-4953090f010f"
      },
      "source": [
        "my_model = models.Sequential()\n",
        "my_model.add(layers.Dense(units = 1, activation = 'linear', input_shape = (36,)))\n",
        "\n",
        "my_model.compile(optimizer = 'adam', loss = 'mean_squared_error')\n",
        "\n",
        "my_model.fit(X_train, y_train,\n",
        "  validation_data = (X_val, y_val),\n",
        "  epochs = 1000, batch_size = 1875)\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Train on 1875 samples, validate on 469 samples\n",
            "Epoch 1/1000\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 37671456768.0000 - val_loss: 35985936384.0000\n",
            "Epoch 2/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 37664890880.0000 - val_loss: 35979571200.0000\n",
            "Epoch 3/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 37658320896.0000 - val_loss: 35973197824.0000\n",
            "Epoch 4/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 37651755008.0000 - val_loss: 35966832640.0000\n",
            "Epoch 5/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 37645185024.0000 - val_loss: 35960463360.0000\n",
            "Epoch 6/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 37638623232.0000 - val_loss: 35954098176.0000\n",
            "Epoch 7/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 37632061440.0000 - val_loss: 35947737088.0000\n",
            "Epoch 8/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 37625491456.0000 - val_loss: 35941367808.0000\n",
            "Epoch 9/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 37618929664.0000 - val_loss: 35935002624.0000\n",
            "Epoch 10/1000\n",
            "1875/1875 [==============================] - 0s 2us/step - loss: 37612371968.0000 - val_loss: 35928641536.0000\n",
            "Epoch 11/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 37605806080.0000 - val_loss: 35922280448.0000\n",
            "Epoch 12/1000\n",
            "1875/1875 [==============================] - 0s 2us/step - loss: 37599248384.0000 - val_loss: 35915919360.0000\n",
            "Epoch 13/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 37592690688.0000 - val_loss: 35909554176.0000\n",
            "Epoch 14/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 37586132992.0000 - val_loss: 35903197184.0000\n",
            "Epoch 15/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 37579571200.0000 - val_loss: 35896840192.0000\n",
            "Epoch 16/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 37573017600.0000 - val_loss: 35890483200.0000\n",
            "Epoch 17/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 37566459904.0000 - val_loss: 35884126208.0000\n",
            "Epoch 18/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 37559906304.0000 - val_loss: 35877773312.0000\n",
            "Epoch 19/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 37553344512.0000 - val_loss: 35871412224.0000\n",
            "Epoch 20/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 37546799104.0000 - val_loss: 35865067520.0000\n",
            "Epoch 21/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 37540241408.0000 - val_loss: 35858710528.0000\n",
            "Epoch 22/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 37533696000.0000 - val_loss: 35852357632.0000\n",
            "Epoch 23/1000\n",
            "1875/1875 [==============================] - 0s 2us/step - loss: 37527146496.0000 - val_loss: 35846008832.0000\n",
            "Epoch 24/1000\n",
            "1875/1875 [==============================] - 0s 2us/step - loss: 37520592896.0000 - val_loss: 35839660032.0000\n",
            "Epoch 25/1000\n",
            "1875/1875 [==============================] - 0s 2us/step - loss: 37514047488.0000 - val_loss: 35833311232.0000\n",
            "Epoch 26/1000\n",
            "1875/1875 [==============================] - 0s 2us/step - loss: 37507497984.0000 - val_loss: 35826962432.0000\n",
            "Epoch 27/1000\n",
            "1875/1875 [==============================] - 0s 2us/step - loss: 37500952576.0000 - val_loss: 35820617728.0000\n",
            "Epoch 28/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 37494407168.0000 - val_loss: 35814268928.0000\n",
            "Epoch 29/1000\n",
            "1875/1875 [==============================] - 0s 2us/step - loss: 37487861760.0000 - val_loss: 35807928320.0000\n",
            "Epoch 30/1000\n",
            "1875/1875 [==============================] - 0s 2us/step - loss: 37481316352.0000 - val_loss: 35801583616.0000\n",
            "Epoch 31/1000\n",
            "1875/1875 [==============================] - 0s 2us/step - loss: 37474775040.0000 - val_loss: 35795243008.0000\n",
            "Epoch 32/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 37468233728.0000 - val_loss: 35788894208.0000\n",
            "Epoch 33/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 37461696512.0000 - val_loss: 35782553600.0000\n",
            "Epoch 34/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 37455155200.0000 - val_loss: 35776221184.0000\n",
            "Epoch 35/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 37448617984.0000 - val_loss: 35769880576.0000\n",
            "Epoch 36/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 37442080768.0000 - val_loss: 35763544064.0000\n",
            "Epoch 37/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 37435543552.0000 - val_loss: 35757207552.0000\n",
            "Epoch 38/1000\n",
            "1875/1875 [==============================] - 0s 2us/step - loss: 37429006336.0000 - val_loss: 35750871040.0000\n",
            "Epoch 39/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 37422473216.0000 - val_loss: 35744534528.0000\n",
            "Epoch 40/1000\n",
            "1875/1875 [==============================] - 0s 2us/step - loss: 37415940096.0000 - val_loss: 35738202112.0000\n",
            "Epoch 41/1000\n",
            "1875/1875 [==============================] - 0s 2us/step - loss: 37409406976.0000 - val_loss: 35731873792.0000\n",
            "Epoch 42/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 37402877952.0000 - val_loss: 35725541376.0000\n",
            "Epoch 43/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 37396348928.0000 - val_loss: 35719208960.0000\n",
            "Epoch 44/1000\n",
            "1875/1875 [==============================] - 0s 6us/step - loss: 37389815808.0000 - val_loss: 35712880640.0000\n",
            "Epoch 45/1000\n",
            "1875/1875 [==============================] - 0s 7us/step - loss: 37383286784.0000 - val_loss: 35706552320.0000\n",
            "Epoch 46/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 37376765952.0000 - val_loss: 35700224000.0000\n",
            "Epoch 47/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 37370241024.0000 - val_loss: 35693899776.0000\n",
            "Epoch 48/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 37363716096.0000 - val_loss: 35687575552.0000\n",
            "Epoch 49/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 37357191168.0000 - val_loss: 35681251328.0000\n",
            "Epoch 50/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 37350670336.0000 - val_loss: 35674931200.0000\n",
            "Epoch 51/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 37344141312.0000 - val_loss: 35668611072.0000\n",
            "Epoch 52/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 37337628672.0000 - val_loss: 35662286848.0000\n",
            "Epoch 53/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 37331107840.0000 - val_loss: 35655966720.0000\n",
            "Epoch 54/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 37324587008.0000 - val_loss: 35649646592.0000\n",
            "Epoch 55/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 37318070272.0000 - val_loss: 35643330560.0000\n",
            "Epoch 56/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 37311553536.0000 - val_loss: 35637014528.0000\n",
            "Epoch 57/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 37305036800.0000 - val_loss: 35630702592.0000\n",
            "Epoch 58/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 37298524160.0000 - val_loss: 35624386560.0000\n",
            "Epoch 59/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 37292011520.0000 - val_loss: 35618074624.0000\n",
            "Epoch 60/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 37285502976.0000 - val_loss: 35611762688.0000\n",
            "Epoch 61/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 37278986240.0000 - val_loss: 35605454848.0000\n",
            "Epoch 62/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 37272477696.0000 - val_loss: 35599142912.0000\n",
            "Epoch 63/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 37265973248.0000 - val_loss: 35592835072.0000\n",
            "Epoch 64/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 37259464704.0000 - val_loss: 35586527232.0000\n",
            "Epoch 65/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 37252956160.0000 - val_loss: 35580223488.0000\n",
            "Epoch 66/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 37246451712.0000 - val_loss: 35573919744.0000\n",
            "Epoch 67/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 37239947264.0000 - val_loss: 35567611904.0000\n",
            "Epoch 68/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 37233442816.0000 - val_loss: 35561312256.0000\n",
            "Epoch 69/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 37226942464.0000 - val_loss: 35555004416.0000\n",
            "Epoch 70/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 37220442112.0000 - val_loss: 35548704768.0000\n",
            "Epoch 71/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 37213941760.0000 - val_loss: 35542405120.0000\n",
            "Epoch 72/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 37207445504.0000 - val_loss: 35536105472.0000\n",
            "Epoch 73/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 37200949248.0000 - val_loss: 35529809920.0000\n",
            "Epoch 74/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 37194448896.0000 - val_loss: 35523514368.0000\n",
            "Epoch 75/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 37187952640.0000 - val_loss: 35517214720.0000\n",
            "Epoch 76/1000\n",
            "1875/1875 [==============================] - 0s 5us/step - loss: 37181456384.0000 - val_loss: 35510923264.0000\n",
            "Epoch 77/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 37174960128.0000 - val_loss: 35504631808.0000\n",
            "Epoch 78/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 37168472064.0000 - val_loss: 35498336256.0000\n",
            "Epoch 79/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 37161979904.0000 - val_loss: 35492044800.0000\n",
            "Epoch 80/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 37155487744.0000 - val_loss: 35485757440.0000\n",
            "Epoch 81/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 37149003776.0000 - val_loss: 35479465984.0000\n",
            "Epoch 82/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 37142511616.0000 - val_loss: 35473182720.0000\n",
            "Epoch 83/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 37136027648.0000 - val_loss: 35466891264.0000\n",
            "Epoch 84/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 37129539584.0000 - val_loss: 35460608000.0000\n",
            "Epoch 85/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 37123051520.0000 - val_loss: 35454320640.0000\n",
            "Epoch 86/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 37116571648.0000 - val_loss: 35448041472.0000\n",
            "Epoch 87/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 37110087680.0000 - val_loss: 35441758208.0000\n",
            "Epoch 88/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 37103607808.0000 - val_loss: 35435474944.0000\n",
            "Epoch 89/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 37097127936.0000 - val_loss: 35429195776.0000\n",
            "Epoch 90/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 37090643968.0000 - val_loss: 35422916608.0000\n",
            "Epoch 91/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 37084168192.0000 - val_loss: 35416637440.0000\n",
            "Epoch 92/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 37077692416.0000 - val_loss: 35410362368.0000\n",
            "Epoch 93/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 37071212544.0000 - val_loss: 35404083200.0000\n",
            "Epoch 94/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 37064740864.0000 - val_loss: 35397812224.0000\n",
            "Epoch 95/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 37058265088.0000 - val_loss: 35391533056.0000\n",
            "Epoch 96/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 37051789312.0000 - val_loss: 35385262080.0000\n",
            "Epoch 97/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 37045317632.0000 - val_loss: 35378991104.0000\n",
            "Epoch 98/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 37038850048.0000 - val_loss: 35372720128.0000\n",
            "Epoch 99/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 37032378368.0000 - val_loss: 35366453248.0000\n",
            "Epoch 100/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 37025906688.0000 - val_loss: 35360186368.0000\n",
            "Epoch 101/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 37019443200.0000 - val_loss: 35353915392.0000\n",
            "Epoch 102/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 37012975616.0000 - val_loss: 35347652608.0000\n",
            "Epoch 103/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 37006508032.0000 - val_loss: 35341385728.0000\n",
            "Epoch 104/1000\n",
            "1875/1875 [==============================] - 0s 6us/step - loss: 37000044544.0000 - val_loss: 35335118848.0000\n",
            "Epoch 105/1000\n",
            "1875/1875 [==============================] - 0s 5us/step - loss: 36993581056.0000 - val_loss: 35328860160.0000\n",
            "Epoch 106/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 36987121664.0000 - val_loss: 35322597376.0000\n",
            "Epoch 107/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 36980658176.0000 - val_loss: 35316334592.0000\n",
            "Epoch 108/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 36974198784.0000 - val_loss: 35310075904.0000\n",
            "Epoch 109/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 36967739392.0000 - val_loss: 35303817216.0000\n",
            "Epoch 110/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 36961284096.0000 - val_loss: 35297562624.0000\n",
            "Epoch 111/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 36954824704.0000 - val_loss: 35291303936.0000\n",
            "Epoch 112/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 36948369408.0000 - val_loss: 35285049344.0000\n",
            "Epoch 113/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 36941914112.0000 - val_loss: 35278790656.0000\n",
            "Epoch 114/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 36935458816.0000 - val_loss: 35272540160.0000\n",
            "Epoch 115/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 36929007616.0000 - val_loss: 35266285568.0000\n",
            "Epoch 116/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 36922552320.0000 - val_loss: 35260035072.0000\n",
            "Epoch 117/1000\n",
            "1875/1875 [==============================] - 0s 5us/step - loss: 36916101120.0000 - val_loss: 35253788672.0000\n",
            "Epoch 118/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 36909654016.0000 - val_loss: 35247538176.0000\n",
            "Epoch 119/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 36903202816.0000 - val_loss: 35241291776.0000\n",
            "Epoch 120/1000\n",
            "1875/1875 [==============================] - 0s 5us/step - loss: 36896755712.0000 - val_loss: 35235041280.0000\n",
            "Epoch 121/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 36890312704.0000 - val_loss: 35228798976.0000\n",
            "Epoch 122/1000\n",
            "1875/1875 [==============================] - 0s 5us/step - loss: 36883869696.0000 - val_loss: 35222552576.0000\n",
            "Epoch 123/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 36877422592.0000 - val_loss: 35216314368.0000\n",
            "Epoch 124/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 36870983680.0000 - val_loss: 35210067968.0000\n",
            "Epoch 125/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 36864540672.0000 - val_loss: 35203825664.0000\n",
            "Epoch 126/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 36858097664.0000 - val_loss: 35197587456.0000\n",
            "Epoch 127/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 36851658752.0000 - val_loss: 35191345152.0000\n",
            "Epoch 128/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 36845219840.0000 - val_loss: 35185106944.0000\n",
            "Epoch 129/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 36838780928.0000 - val_loss: 35178876928.0000\n",
            "Epoch 130/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 36832346112.0000 - val_loss: 35172634624.0000\n",
            "Epoch 131/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 36825907200.0000 - val_loss: 35166400512.0000\n",
            "Epoch 132/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 36819476480.0000 - val_loss: 35160170496.0000\n",
            "Epoch 133/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 36813045760.0000 - val_loss: 35153936384.0000\n",
            "Epoch 134/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 36806606848.0000 - val_loss: 35147702272.0000\n",
            "Epoch 135/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 36800180224.0000 - val_loss: 35141468160.0000\n",
            "Epoch 136/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 36793741312.0000 - val_loss: 35135242240.0000\n",
            "Epoch 137/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 36787314688.0000 - val_loss: 35129012224.0000\n",
            "Epoch 138/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 36780892160.0000 - val_loss: 35122782208.0000\n",
            "Epoch 139/1000\n",
            "1875/1875 [==============================] - 0s 6us/step - loss: 36774461440.0000 - val_loss: 35116556288.0000\n",
            "Epoch 140/1000\n",
            "1875/1875 [==============================] - 0s 7us/step - loss: 36768034816.0000 - val_loss: 35110334464.0000\n",
            "Epoch 141/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 36761608192.0000 - val_loss: 35104108544.0000\n",
            "Epoch 142/1000\n",
            "1875/1875 [==============================] - 0s 5us/step - loss: 36755189760.0000 - val_loss: 35097882624.0000\n",
            "Epoch 143/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 36748767232.0000 - val_loss: 35091664896.0000\n",
            "Epoch 144/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 36742344704.0000 - val_loss: 35085447168.0000\n",
            "Epoch 145/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 36735918080.0000 - val_loss: 35079225344.0000\n",
            "Epoch 146/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 36729499648.0000 - val_loss: 35073007616.0000\n",
            "Epoch 147/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 36723085312.0000 - val_loss: 35066785792.0000\n",
            "Epoch 148/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 36716662784.0000 - val_loss: 35060572160.0000\n",
            "Epoch 149/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 36710252544.0000 - val_loss: 35054354432.0000\n",
            "Epoch 150/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 36703838208.0000 - val_loss: 35048140800.0000\n",
            "Epoch 151/1000\n",
            "1875/1875 [==============================] - 0s 5us/step - loss: 36697419776.0000 - val_loss: 35041927168.0000\n",
            "Epoch 152/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 36691005440.0000 - val_loss: 35035717632.0000\n",
            "Epoch 153/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 36684599296.0000 - val_loss: 35029504000.0000\n",
            "Epoch 154/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 36678184960.0000 - val_loss: 35023294464.0000\n",
            "Epoch 155/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 36671774720.0000 - val_loss: 35017084928.0000\n",
            "Epoch 156/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 36665360384.0000 - val_loss: 35010875392.0000\n",
            "Epoch 157/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 36658958336.0000 - val_loss: 35004669952.0000\n",
            "Epoch 158/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 36652552192.0000 - val_loss: 34998460416.0000\n",
            "Epoch 159/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 36646141952.0000 - val_loss: 34992259072.0000\n",
            "Epoch 160/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 36639735808.0000 - val_loss: 34986053632.0000\n",
            "Epoch 161/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 36633333760.0000 - val_loss: 34979852288.0000\n",
            "Epoch 162/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 36626931712.0000 - val_loss: 34973650944.0000\n",
            "Epoch 163/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 36620533760.0000 - val_loss: 34967445504.0000\n",
            "Epoch 164/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 36614127616.0000 - val_loss: 34961248256.0000\n",
            "Epoch 165/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 36607729664.0000 - val_loss: 34955051008.0000\n",
            "Epoch 166/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 36601331712.0000 - val_loss: 34948853760.0000\n",
            "Epoch 167/1000\n",
            "1875/1875 [==============================] - 0s 5us/step - loss: 36594933760.0000 - val_loss: 34942656512.0000\n",
            "Epoch 168/1000\n",
            "1875/1875 [==============================] - 0s 8us/step - loss: 36588539904.0000 - val_loss: 34936463360.0000\n",
            "Epoch 169/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 36582141952.0000 - val_loss: 34930266112.0000\n",
            "Epoch 170/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 36575752192.0000 - val_loss: 34924077056.0000\n",
            "Epoch 171/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 36569358336.0000 - val_loss: 34917883904.0000\n",
            "Epoch 172/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 36562964480.0000 - val_loss: 34911690752.0000\n",
            "Epoch 173/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 36556574720.0000 - val_loss: 34905501696.0000\n",
            "Epoch 174/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 36550180864.0000 - val_loss: 34899312640.0000\n",
            "Epoch 175/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 36543791104.0000 - val_loss: 34893123584.0000\n",
            "Epoch 176/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 36537405440.0000 - val_loss: 34886938624.0000\n",
            "Epoch 177/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 36531023872.0000 - val_loss: 34880749568.0000\n",
            "Epoch 178/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 36524634112.0000 - val_loss: 34874568704.0000\n",
            "Epoch 179/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 36518248448.0000 - val_loss: 34868383744.0000\n",
            "Epoch 180/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 36511866880.0000 - val_loss: 34862202880.0000\n",
            "Epoch 181/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 36505481216.0000 - val_loss: 34856022016.0000\n",
            "Epoch 182/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 36499103744.0000 - val_loss: 34849841152.0000\n",
            "Epoch 183/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 36492726272.0000 - val_loss: 34843656192.0000\n",
            "Epoch 184/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 36486340608.0000 - val_loss: 34837483520.0000\n",
            "Epoch 185/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 36479963136.0000 - val_loss: 34831302656.0000\n",
            "Epoch 186/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 36473585664.0000 - val_loss: 34825125888.0000\n",
            "Epoch 187/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 36467212288.0000 - val_loss: 34818953216.0000\n",
            "Epoch 188/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 36460830720.0000 - val_loss: 34812780544.0000\n",
            "Epoch 189/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 36454461440.0000 - val_loss: 34806607872.0000\n",
            "Epoch 190/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 36448088064.0000 - val_loss: 34800435200.0000\n",
            "Epoch 191/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 36441710592.0000 - val_loss: 34794266624.0000\n",
            "Epoch 192/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 36435345408.0000 - val_loss: 34788093952.0000\n",
            "Epoch 193/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 36428976128.0000 - val_loss: 34781925376.0000\n",
            "Epoch 194/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 36422606848.0000 - val_loss: 34775756800.0000\n",
            "Epoch 195/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 36416237568.0000 - val_loss: 34769592320.0000\n",
            "Epoch 196/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 36409872384.0000 - val_loss: 34763423744.0000\n",
            "Epoch 197/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 36403507200.0000 - val_loss: 34757259264.0000\n",
            "Epoch 198/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 36397137920.0000 - val_loss: 34751094784.0000\n",
            "Epoch 199/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 36390780928.0000 - val_loss: 34744938496.0000\n",
            "Epoch 200/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 36384415744.0000 - val_loss: 34738774016.0000\n",
            "Epoch 201/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 36378054656.0000 - val_loss: 34732613632.0000\n",
            "Epoch 202/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 36371697664.0000 - val_loss: 34726457344.0000\n",
            "Epoch 203/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 36365332480.0000 - val_loss: 34720296960.0000\n",
            "Epoch 204/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 36358975488.0000 - val_loss: 34714140672.0000\n",
            "Epoch 205/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 36352618496.0000 - val_loss: 34707980288.0000\n",
            "Epoch 206/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 36346261504.0000 - val_loss: 34701824000.0000\n",
            "Epoch 207/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 36339908608.0000 - val_loss: 34695675904.0000\n",
            "Epoch 208/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 36333555712.0000 - val_loss: 34689519616.0000\n",
            "Epoch 209/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 36327198720.0000 - val_loss: 34683371520.0000\n",
            "Epoch 210/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 36320849920.0000 - val_loss: 34677219328.0000\n",
            "Epoch 211/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 36314497024.0000 - val_loss: 34671071232.0000\n",
            "Epoch 212/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 36308148224.0000 - val_loss: 34664919040.0000\n",
            "Epoch 213/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 36301799424.0000 - val_loss: 34658770944.0000\n",
            "Epoch 214/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 36295450624.0000 - val_loss: 34652626944.0000\n",
            "Epoch 215/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 36289105920.0000 - val_loss: 34646482944.0000\n",
            "Epoch 216/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 36282757120.0000 - val_loss: 34640334848.0000\n",
            "Epoch 217/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 36276412416.0000 - val_loss: 34634194944.0000\n",
            "Epoch 218/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 36270067712.0000 - val_loss: 34628050944.0000\n",
            "Epoch 219/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 36263727104.0000 - val_loss: 34621911040.0000\n",
            "Epoch 220/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 36257390592.0000 - val_loss: 34615771136.0000\n",
            "Epoch 221/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 36251045888.0000 - val_loss: 34609631232.0000\n",
            "Epoch 222/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 36244705280.0000 - val_loss: 34603491328.0000\n",
            "Epoch 223/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 36238368768.0000 - val_loss: 34597359616.0000\n",
            "Epoch 224/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 36232028160.0000 - val_loss: 34591219712.0000\n",
            "Epoch 225/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 36225691648.0000 - val_loss: 34585088000.0000\n",
            "Epoch 226/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 36219359232.0000 - val_loss: 34578952192.0000\n",
            "Epoch 227/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 36213022720.0000 - val_loss: 34572816384.0000\n",
            "Epoch 228/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 36206690304.0000 - val_loss: 34566684672.0000\n",
            "Epoch 229/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 36200361984.0000 - val_loss: 34560557056.0000\n",
            "Epoch 230/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 36194025472.0000 - val_loss: 34554429440.0000\n",
            "Epoch 231/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 36187697152.0000 - val_loss: 34548297728.0000\n",
            "Epoch 232/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 36181368832.0000 - val_loss: 34542174208.0000\n",
            "Epoch 233/1000\n",
            "1875/1875 [==============================] - 0s 6us/step - loss: 36175040512.0000 - val_loss: 34536046592.0000\n",
            "Epoch 234/1000\n",
            "1875/1875 [==============================] - 0s 6us/step - loss: 36168716288.0000 - val_loss: 34529918976.0000\n",
            "Epoch 235/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 36162387968.0000 - val_loss: 34523795456.0000\n",
            "Epoch 236/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 36156063744.0000 - val_loss: 34517676032.0000\n",
            "Epoch 237/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 36149743616.0000 - val_loss: 34511548416.0000\n",
            "Epoch 238/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 36143419392.0000 - val_loss: 34505428992.0000\n",
            "Epoch 239/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 36137095168.0000 - val_loss: 34499309568.0000\n",
            "Epoch 240/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 36130775040.0000 - val_loss: 34493190144.0000\n",
            "Epoch 241/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 36124454912.0000 - val_loss: 34487070720.0000\n",
            "Epoch 242/1000\n",
            "1875/1875 [==============================] - 0s 5us/step - loss: 36118134784.0000 - val_loss: 34480955392.0000\n",
            "Epoch 243/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 36111822848.0000 - val_loss: 34474840064.0000\n",
            "Epoch 244/1000\n",
            "1875/1875 [==============================] - 0s 2us/step - loss: 36105506816.0000 - val_loss: 34468724736.0000\n",
            "Epoch 245/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 36099186688.0000 - val_loss: 34462609408.0000\n",
            "Epoch 246/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 36092874752.0000 - val_loss: 34456498176.0000\n",
            "Epoch 247/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 36086562816.0000 - val_loss: 34450386944.0000\n",
            "Epoch 248/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 36080246784.0000 - val_loss: 34444275712.0000\n",
            "Epoch 249/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 36073934848.0000 - val_loss: 34438164480.0000\n",
            "Epoch 250/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 36067627008.0000 - val_loss: 34432053248.0000\n",
            "Epoch 251/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 36061315072.0000 - val_loss: 34425950208.0000\n",
            "Epoch 252/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 36055007232.0000 - val_loss: 34419843072.0000\n",
            "Epoch 253/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 36048703488.0000 - val_loss: 34413740032.0000\n",
            "Epoch 254/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 36042395648.0000 - val_loss: 34407636992.0000\n",
            "Epoch 255/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 36036091904.0000 - val_loss: 34401533952.0000\n",
            "Epoch 256/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 36029788160.0000 - val_loss: 34395426816.0000\n",
            "Epoch 257/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 36023480320.0000 - val_loss: 34389327872.0000\n",
            "Epoch 258/1000\n",
            "1875/1875 [==============================] - 0s 5us/step - loss: 36017184768.0000 - val_loss: 34383224832.0000\n",
            "Epoch 259/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 36010881024.0000 - val_loss: 34377129984.0000\n",
            "Epoch 260/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 36004581376.0000 - val_loss: 34371031040.0000\n",
            "Epoch 261/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 35998281728.0000 - val_loss: 34364932096.0000\n",
            "Epoch 262/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 35991986176.0000 - val_loss: 34358837248.0000\n",
            "Epoch 263/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 35985686528.0000 - val_loss: 34352744448.0000\n",
            "Epoch 264/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 35979390976.0000 - val_loss: 34346649600.0000\n",
            "Epoch 265/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 35973099520.0000 - val_loss: 34340554752.0000\n",
            "Epoch 266/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 35966803968.0000 - val_loss: 34334464000.0000\n",
            "Epoch 267/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 35960516608.0000 - val_loss: 34328371200.0000\n",
            "Epoch 268/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 35954221056.0000 - val_loss: 34322280448.0000\n",
            "Epoch 269/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 35947929600.0000 - val_loss: 34316191744.0000\n",
            "Epoch 270/1000\n",
            "1875/1875 [==============================] - 0s 2us/step - loss: 35941642240.0000 - val_loss: 34310107136.0000\n",
            "Epoch 271/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 35935350784.0000 - val_loss: 34304018432.0000\n",
            "Epoch 272/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 35929067520.0000 - val_loss: 34297931776.0000\n",
            "Epoch 273/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 35922776064.0000 - val_loss: 34291849216.0000\n",
            "Epoch 274/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 35916492800.0000 - val_loss: 34285766656.0000\n",
            "Epoch 275/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 35910209536.0000 - val_loss: 34279684096.0000\n",
            "Epoch 276/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 35903926272.0000 - val_loss: 34273605632.0000\n",
            "Epoch 277/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 35897643008.0000 - val_loss: 34267521024.0000\n",
            "Epoch 278/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 35891363840.0000 - val_loss: 34261440512.0000\n",
            "Epoch 279/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 35885084672.0000 - val_loss: 34255366144.0000\n",
            "Epoch 280/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 35878801408.0000 - val_loss: 34249289728.0000\n",
            "Epoch 281/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 35872526336.0000 - val_loss: 34243209216.0000\n",
            "Epoch 282/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 35866251264.0000 - val_loss: 34237136896.0000\n",
            "Epoch 283/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 35859972096.0000 - val_loss: 34231064576.0000\n",
            "Epoch 284/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 35853701120.0000 - val_loss: 34224988160.0000\n",
            "Epoch 285/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 35847426048.0000 - val_loss: 34218917888.0000\n",
            "Epoch 286/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 35841150976.0000 - val_loss: 34212845568.0000\n",
            "Epoch 287/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 35834880000.0000 - val_loss: 34206775296.0000\n",
            "Epoch 288/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 35828609024.0000 - val_loss: 34200707072.0000\n",
            "Epoch 289/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 35822342144.0000 - val_loss: 34194642944.0000\n",
            "Epoch 290/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 35816067072.0000 - val_loss: 34188572672.0000\n",
            "Epoch 291/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 35809804288.0000 - val_loss: 34182506496.0000\n",
            "Epoch 292/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 35803537408.0000 - val_loss: 34176440320.0000\n",
            "Epoch 293/1000\n",
            "1875/1875 [==============================] - 0s 5us/step - loss: 35797274624.0000 - val_loss: 34170380288.0000\n",
            "Epoch 294/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 35791007744.0000 - val_loss: 34164318208.0000\n",
            "Epoch 295/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 35784744960.0000 - val_loss: 34158258176.0000\n",
            "Epoch 296/1000\n",
            "1875/1875 [==============================] - 0s 5us/step - loss: 35778482176.0000 - val_loss: 34152196096.0000\n",
            "Epoch 297/1000\n",
            "1875/1875 [==============================] - 0s 5us/step - loss: 35772219392.0000 - val_loss: 34146138112.0000\n",
            "Epoch 298/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 35765956608.0000 - val_loss: 34140076032.0000\n",
            "Epoch 299/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 35759702016.0000 - val_loss: 34134020096.0000\n",
            "Epoch 300/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 35753443328.0000 - val_loss: 34127968256.0000\n",
            "Epoch 301/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 35747184640.0000 - val_loss: 34121908224.0000\n",
            "Epoch 302/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 35740925952.0000 - val_loss: 34115856384.0000\n",
            "Epoch 303/1000\n",
            "1875/1875 [==============================] - 0s 2us/step - loss: 35734675456.0000 - val_loss: 34109802496.0000\n",
            "Epoch 304/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 35728420864.0000 - val_loss: 34103748608.0000\n",
            "Epoch 305/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 35722166272.0000 - val_loss: 34097698816.0000\n",
            "Epoch 306/1000\n",
            "1875/1875 [==============================] - 0s 5us/step - loss: 35715915776.0000 - val_loss: 34091649024.0000\n",
            "Epoch 307/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 35709661184.0000 - val_loss: 34085599232.0000\n",
            "Epoch 308/1000\n",
            "1875/1875 [==============================] - 0s 2us/step - loss: 35703414784.0000 - val_loss: 34079549440.0000\n",
            "Epoch 309/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 35697160192.0000 - val_loss: 34073501696.0000\n",
            "Epoch 310/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 35690913792.0000 - val_loss: 34067460096.0000\n",
            "Epoch 311/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 35684667392.0000 - val_loss: 34061414400.0000\n",
            "Epoch 312/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 35678420992.0000 - val_loss: 34055368704.0000\n",
            "Epoch 313/1000\n",
            "1875/1875 [==============================] - 0s 2us/step - loss: 35672174592.0000 - val_loss: 34049327104.0000\n",
            "Epoch 314/1000\n",
            "1875/1875 [==============================] - 0s 2us/step - loss: 35665932288.0000 - val_loss: 34043285504.0000\n",
            "Epoch 315/1000\n",
            "1875/1875 [==============================] - 0s 2us/step - loss: 35659689984.0000 - val_loss: 34037243904.0000\n",
            "Epoch 316/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 35653447680.0000 - val_loss: 34031202304.0000\n",
            "Epoch 317/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 35647205376.0000 - val_loss: 34025166848.0000\n",
            "Epoch 318/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 35640967168.0000 - val_loss: 34019127296.0000\n",
            "Epoch 319/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 35634728960.0000 - val_loss: 34013091840.0000\n",
            "Epoch 320/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 35628490752.0000 - val_loss: 34007056384.0000\n",
            "Epoch 321/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 35622252544.0000 - val_loss: 34001022976.0000\n",
            "Epoch 322/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 35616018432.0000 - val_loss: 33994985472.0000\n",
            "Epoch 323/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 35609784320.0000 - val_loss: 33988954112.0000\n",
            "Epoch 324/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 35603546112.0000 - val_loss: 33982926848.0000\n",
            "Epoch 325/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 35597316096.0000 - val_loss: 33976891392.0000\n",
            "Epoch 326/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 35591086080.0000 - val_loss: 33970864128.0000\n",
            "Epoch 327/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 35584856064.0000 - val_loss: 33964834816.0000\n",
            "Epoch 328/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 35578626048.0000 - val_loss: 33958809600.0000\n",
            "Epoch 329/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 35572396032.0000 - val_loss: 33952782336.0000\n",
            "Epoch 330/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 35566166016.0000 - val_loss: 33946759168.0000\n",
            "Epoch 331/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 35559944192.0000 - val_loss: 33940731904.0000\n",
            "Epoch 332/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 35553718272.0000 - val_loss: 33934714880.0000\n",
            "Epoch 333/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 35547492352.0000 - val_loss: 33928685568.0000\n",
            "Epoch 334/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 35541270528.0000 - val_loss: 33922668544.0000\n",
            "Epoch 335/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 35535048704.0000 - val_loss: 33916645376.0000\n",
            "Epoch 336/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 35528822784.0000 - val_loss: 33910628352.0000\n",
            "Epoch 337/1000\n",
            "1875/1875 [==============================] - 0s 2us/step - loss: 35522605056.0000 - val_loss: 33904611328.0000\n",
            "Epoch 338/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 35516387328.0000 - val_loss: 33898592256.0000\n",
            "Epoch 339/1000\n",
            "1875/1875 [==============================] - 0s 2us/step - loss: 35510169600.0000 - val_loss: 33892579328.0000\n",
            "Epoch 340/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 35503951872.0000 - val_loss: 33886560256.0000\n",
            "Epoch 341/1000\n",
            "1875/1875 [==============================] - 0s 2us/step - loss: 35497734144.0000 - val_loss: 33880547328.0000\n",
            "Epoch 342/1000\n",
            "1875/1875 [==============================] - 0s 2us/step - loss: 35491524608.0000 - val_loss: 33874536448.0000\n",
            "Epoch 343/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 35485302784.0000 - val_loss: 33868521472.0000\n",
            "Epoch 344/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 35479089152.0000 - val_loss: 33862512640.0000\n",
            "Epoch 345/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 35472879616.0000 - val_loss: 33856501760.0000\n",
            "Epoch 346/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 35466665984.0000 - val_loss: 33850494976.0000\n",
            "Epoch 347/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 35460460544.0000 - val_loss: 33844484096.0000\n",
            "Epoch 348/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 35454251008.0000 - val_loss: 33838481408.0000\n",
            "Epoch 349/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 35448041472.0000 - val_loss: 33832474624.0000\n",
            "Epoch 350/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 35441831936.0000 - val_loss: 33826467840.0000\n",
            "Epoch 351/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 35435630592.0000 - val_loss: 33820463104.0000\n",
            "Epoch 352/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 35429425152.0000 - val_loss: 33814464512.0000\n",
            "Epoch 353/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 35423219712.0000 - val_loss: 33808463872.0000\n",
            "Epoch 354/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 35417014272.0000 - val_loss: 33802459136.0000\n",
            "Epoch 355/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 35410808832.0000 - val_loss: 33796460544.0000\n",
            "Epoch 356/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 35404611584.0000 - val_loss: 33790466048.0000\n",
            "Epoch 357/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 35398410240.0000 - val_loss: 33784463360.0000\n",
            "Epoch 358/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 35392212992.0000 - val_loss: 33778466816.0000\n",
            "Epoch 359/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 35386015744.0000 - val_loss: 33772476416.0000\n",
            "Epoch 360/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 35379818496.0000 - val_loss: 33766477824.0000\n",
            "Epoch 361/1000\n",
            "1875/1875 [==============================] - 0s 2us/step - loss: 35373625344.0000 - val_loss: 33760485376.0000\n",
            "Epoch 362/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 35367428096.0000 - val_loss: 33754492928.0000\n",
            "Epoch 363/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 35361234944.0000 - val_loss: 33748502528.0000\n",
            "Epoch 364/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 35355037696.0000 - val_loss: 33742514176.0000\n",
            "Epoch 365/1000\n",
            "1875/1875 [==============================] - 0s 5us/step - loss: 35348852736.0000 - val_loss: 33736521728.0000\n",
            "Epoch 366/1000\n",
            "1875/1875 [==============================] - 0s 5us/step - loss: 35342659584.0000 - val_loss: 33730535424.0000\n",
            "Epoch 367/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 35336466432.0000 - val_loss: 33724547072.0000\n",
            "Epoch 368/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 35330281472.0000 - val_loss: 33718562816.0000\n",
            "Epoch 369/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 35324092416.0000 - val_loss: 33712574464.0000\n",
            "Epoch 370/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 35317903360.0000 - val_loss: 33706592256.0000\n",
            "Epoch 371/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 35311726592.0000 - val_loss: 33700608000.0000\n",
            "Epoch 372/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 35305537536.0000 - val_loss: 33694623744.0000\n",
            "Epoch 373/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 35299356672.0000 - val_loss: 33688645632.0000\n",
            "Epoch 374/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 35293171712.0000 - val_loss: 33682669568.0000\n",
            "Epoch 375/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 35286986752.0000 - val_loss: 33676685312.0000\n",
            "Epoch 376/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 35280805888.0000 - val_loss: 33670709248.0000\n",
            "Epoch 377/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 35274629120.0000 - val_loss: 33664733184.0000\n",
            "Epoch 378/1000\n",
            "1875/1875 [==============================] - 0s 2us/step - loss: 35268452352.0000 - val_loss: 33658757120.0000\n",
            "Epoch 379/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 35262271488.0000 - val_loss: 33652783104.0000\n",
            "Epoch 380/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 35256094720.0000 - val_loss: 33646807040.0000\n",
            "Epoch 381/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 35249922048.0000 - val_loss: 33640835072.0000\n",
            "Epoch 382/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 35243745280.0000 - val_loss: 33634863104.0000\n",
            "Epoch 383/1000\n",
            "1875/1875 [==============================] - 0s 2us/step - loss: 35237572608.0000 - val_loss: 33628895232.0000\n",
            "Epoch 384/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 35231399936.0000 - val_loss: 33622923264.0000\n",
            "Epoch 385/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 35225227264.0000 - val_loss: 33616953344.0000\n",
            "Epoch 386/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 35219058688.0000 - val_loss: 33610987520.0000\n",
            "Epoch 387/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 35212886016.0000 - val_loss: 33605021696.0000\n",
            "Epoch 388/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 35206717440.0000 - val_loss: 33599055872.0000\n",
            "Epoch 389/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 35200552960.0000 - val_loss: 33593088000.0000\n",
            "Epoch 390/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 35194388480.0000 - val_loss: 33587128320.0000\n",
            "Epoch 391/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 35188224000.0000 - val_loss: 33581162496.0000\n",
            "Epoch 392/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 35182055424.0000 - val_loss: 33575200768.0000\n",
            "Epoch 393/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 35175895040.0000 - val_loss: 33569241088.0000\n",
            "Epoch 394/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 35169734656.0000 - val_loss: 33563283456.0000\n",
            "Epoch 395/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 35163570176.0000 - val_loss: 33557325824.0000\n",
            "Epoch 396/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 35157409792.0000 - val_loss: 33551364096.0000\n",
            "Epoch 397/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 35151253504.0000 - val_loss: 33545410560.0000\n",
            "Epoch 398/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 35145093120.0000 - val_loss: 33539454976.0000\n",
            "Epoch 399/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 35138936832.0000 - val_loss: 33533501440.0000\n",
            "Epoch 400/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 35132780544.0000 - val_loss: 33527545856.0000\n",
            "Epoch 401/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 35126624256.0000 - val_loss: 33521592320.0000\n",
            "Epoch 402/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 35120472064.0000 - val_loss: 33515642880.0000\n",
            "Epoch 403/1000\n",
            "1875/1875 [==============================] - 0s 5us/step - loss: 35114315776.0000 - val_loss: 33509693440.0000\n",
            "Epoch 404/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 35108163584.0000 - val_loss: 33503741952.0000\n",
            "Epoch 405/1000\n",
            "1875/1875 [==============================] - 0s 6us/step - loss: 35102015488.0000 - val_loss: 33497792512.0000\n",
            "Epoch 406/1000\n",
            "1875/1875 [==============================] - 0s 5us/step - loss: 35095859200.0000 - val_loss: 33491849216.0000\n",
            "Epoch 407/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 35089711104.0000 - val_loss: 33485901824.0000\n",
            "Epoch 408/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 35083567104.0000 - val_loss: 33479954432.0000\n",
            "Epoch 409/1000\n",
            "1875/1875 [==============================] - 0s 5us/step - loss: 35077419008.0000 - val_loss: 33474011136.0000\n",
            "Epoch 410/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 35071275008.0000 - val_loss: 33468067840.0000\n",
            "Epoch 411/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 35065131008.0000 - val_loss: 33462126592.0000\n",
            "Epoch 412/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 35058982912.0000 - val_loss: 33456181248.0000\n",
            "Epoch 413/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 35052838912.0000 - val_loss: 33450246144.0000\n",
            "Epoch 414/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 35046699008.0000 - val_loss: 33444302848.0000\n",
            "Epoch 415/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 35040555008.0000 - val_loss: 33438365696.0000\n",
            "Epoch 416/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 35034415104.0000 - val_loss: 33432430592.0000\n",
            "Epoch 417/1000\n",
            "1875/1875 [==============================] - 0s 5us/step - loss: 35028275200.0000 - val_loss: 33426495488.0000\n",
            "Epoch 418/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 35022139392.0000 - val_loss: 33420558336.0000\n",
            "Epoch 419/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 35016003584.0000 - val_loss: 33414625280.0000\n",
            "Epoch 420/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 35009867776.0000 - val_loss: 33408690176.0000\n",
            "Epoch 421/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 35003731968.0000 - val_loss: 33402757120.0000\n",
            "Epoch 422/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 34997600256.0000 - val_loss: 33396828160.0000\n",
            "Epoch 423/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 34991464448.0000 - val_loss: 33390899200.0000\n",
            "Epoch 424/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 34985336832.0000 - val_loss: 33384970240.0000\n",
            "Epoch 425/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 34979201024.0000 - val_loss: 33379041280.0000\n",
            "Epoch 426/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 34973069312.0000 - val_loss: 33373112320.0000\n",
            "Epoch 427/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 34966945792.0000 - val_loss: 33367189504.0000\n",
            "Epoch 428/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 34960814080.0000 - val_loss: 33361264640.0000\n",
            "Epoch 429/1000\n",
            "1875/1875 [==============================] - 0s 2us/step - loss: 34954686464.0000 - val_loss: 33355341824.0000\n",
            "Epoch 430/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 34948562944.0000 - val_loss: 33349414912.0000\n",
            "Epoch 431/1000\n",
            "1875/1875 [==============================] - 0s 6us/step - loss: 34942439424.0000 - val_loss: 33343496192.0000\n",
            "Epoch 432/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 34936311808.0000 - val_loss: 33337573376.0000\n",
            "Epoch 433/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 34930192384.0000 - val_loss: 33331654656.0000\n",
            "Epoch 434/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 34924068864.0000 - val_loss: 33325737984.0000\n",
            "Epoch 435/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 34917949440.0000 - val_loss: 33319817216.0000\n",
            "Epoch 436/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 34911825920.0000 - val_loss: 33313900544.0000\n",
            "Epoch 437/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 34905706496.0000 - val_loss: 33307983872.0000\n",
            "Epoch 438/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 34899587072.0000 - val_loss: 33302069248.0000\n",
            "Epoch 439/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 34893471744.0000 - val_loss: 33296158720.0000\n",
            "Epoch 440/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 34887356416.0000 - val_loss: 33290242048.0000\n",
            "Epoch 441/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 34881241088.0000 - val_loss: 33284333568.0000\n",
            "Epoch 442/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 34875125760.0000 - val_loss: 33278416896.0000\n",
            "Epoch 443/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 34869014528.0000 - val_loss: 33272512512.0000\n",
            "Epoch 444/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 34862903296.0000 - val_loss: 33266604032.0000\n",
            "Epoch 445/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 34856792064.0000 - val_loss: 33260693504.0000\n",
            "Epoch 446/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 34850684928.0000 - val_loss: 33254789120.0000\n",
            "Epoch 447/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 34844573696.0000 - val_loss: 33248882688.0000\n",
            "Epoch 448/1000\n",
            "1875/1875 [==============================] - 0s 5us/step - loss: 34838466560.0000 - val_loss: 33242976256.0000\n",
            "Epoch 449/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 34832359424.0000 - val_loss: 33237071872.0000\n",
            "Epoch 450/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 34826256384.0000 - val_loss: 33231171584.0000\n",
            "Epoch 451/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 34820153344.0000 - val_loss: 33225269248.0000\n",
            "Epoch 452/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 34814046208.0000 - val_loss: 33219371008.0000\n",
            "Epoch 453/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 34807943168.0000 - val_loss: 33213470720.0000\n",
            "Epoch 454/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 34801840128.0000 - val_loss: 33207572480.0000\n",
            "Epoch 455/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 34795737088.0000 - val_loss: 33201670144.0000\n",
            "Epoch 456/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 34789638144.0000 - val_loss: 33195773952.0000\n",
            "Epoch 457/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 34783539200.0000 - val_loss: 33189883904.0000\n",
            "Epoch 458/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 34777444352.0000 - val_loss: 33183987712.0000\n",
            "Epoch 459/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 34771345408.0000 - val_loss: 33178091520.0000\n",
            "Epoch 460/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 34765254656.0000 - val_loss: 33172199424.0000\n",
            "Epoch 461/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 34759155712.0000 - val_loss: 33166307328.0000\n",
            "Epoch 462/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 34753060864.0000 - val_loss: 33160415232.0000\n",
            "Epoch 463/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 34746966016.0000 - val_loss: 33154527232.0000\n",
            "Epoch 464/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 34740879360.0000 - val_loss: 33148637184.0000\n",
            "Epoch 465/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 34734784512.0000 - val_loss: 33142751232.0000\n",
            "Epoch 466/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 34728693760.0000 - val_loss: 33136865280.0000\n",
            "Epoch 467/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 34722603008.0000 - val_loss: 33130977280.0000\n",
            "Epoch 468/1000\n",
            "1875/1875 [==============================] - 0s 5us/step - loss: 34716520448.0000 - val_loss: 33125093376.0000\n",
            "Epoch 469/1000\n",
            "1875/1875 [==============================] - 0s 5us/step - loss: 34710433792.0000 - val_loss: 33119209472.0000\n",
            "Epoch 470/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 34704343040.0000 - val_loss: 33113327616.0000\n",
            "Epoch 471/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 34698260480.0000 - val_loss: 33107447808.0000\n",
            "Epoch 472/1000\n",
            "1875/1875 [==============================] - 0s 5us/step - loss: 34692177920.0000 - val_loss: 33101568000.0000\n",
            "Epoch 473/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 34686091264.0000 - val_loss: 33095688192.0000\n",
            "Epoch 474/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 34680012800.0000 - val_loss: 33089810432.0000\n",
            "Epoch 475/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 34673930240.0000 - val_loss: 33083934720.0000\n",
            "Epoch 476/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 34667851776.0000 - val_loss: 33078056960.0000\n",
            "Epoch 477/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 34661773312.0000 - val_loss: 33072181248.0000\n",
            "Epoch 478/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 34655694848.0000 - val_loss: 33066305536.0000\n",
            "Epoch 479/1000\n",
            "1875/1875 [==============================] - 0s 2us/step - loss: 34649616384.0000 - val_loss: 33060431872.0000\n",
            "Epoch 480/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 34643542016.0000 - val_loss: 33054558208.0000\n",
            "Epoch 481/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 34637467648.0000 - val_loss: 33048686592.0000\n",
            "Epoch 482/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 34631389184.0000 - val_loss: 33042819072.0000\n",
            "Epoch 483/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 34625318912.0000 - val_loss: 33036945408.0000\n",
            "Epoch 484/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 34619244544.0000 - val_loss: 33031077888.0000\n",
            "Epoch 485/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 34613174272.0000 - val_loss: 33025212416.0000\n",
            "Epoch 486/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 34607108096.0000 - val_loss: 33019342848.0000\n",
            "Epoch 487/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 34601037824.0000 - val_loss: 33013481472.0000\n",
            "Epoch 488/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 34594967552.0000 - val_loss: 33007613952.0000\n",
            "Epoch 489/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 34588901376.0000 - val_loss: 33001754624.0000\n",
            "Epoch 490/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 34582835200.0000 - val_loss: 32995889152.0000\n",
            "Epoch 491/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 34576769024.0000 - val_loss: 32990025728.0000\n",
            "Epoch 492/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 34570706944.0000 - val_loss: 32984166400.0000\n",
            "Epoch 493/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 34564644864.0000 - val_loss: 32978305024.0000\n",
            "Epoch 494/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 34558582784.0000 - val_loss: 32972447744.0000\n",
            "Epoch 495/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 34552520704.0000 - val_loss: 32966592512.0000\n",
            "Epoch 496/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 34546458624.0000 - val_loss: 32960735232.0000\n",
            "Epoch 497/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 34540400640.0000 - val_loss: 32954880000.0000\n",
            "Epoch 498/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 34534342656.0000 - val_loss: 32949022720.0000\n",
            "Epoch 499/1000\n",
            "1875/1875 [==============================] - 0s 5us/step - loss: 34528284672.0000 - val_loss: 32943169536.0000\n",
            "Epoch 500/1000\n",
            "1875/1875 [==============================] - 0s 5us/step - loss: 34522230784.0000 - val_loss: 32937318400.0000\n",
            "Epoch 501/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 34516176896.0000 - val_loss: 32931469312.0000\n",
            "Epoch 502/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 34510118912.0000 - val_loss: 32925620224.0000\n",
            "Epoch 503/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 34504069120.0000 - val_loss: 32919767040.0000\n",
            "Epoch 504/1000\n",
            "1875/1875 [==============================] - 0s 5us/step - loss: 34498015232.0000 - val_loss: 32913920000.0000\n",
            "Epoch 505/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 34491965440.0000 - val_loss: 32908072960.0000\n",
            "Epoch 506/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 34485915648.0000 - val_loss: 32902223872.0000\n",
            "Epoch 507/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 34479865856.0000 - val_loss: 32896378880.0000\n",
            "Epoch 508/1000\n",
            "1875/1875 [==============================] - 0s 5us/step - loss: 34473816064.0000 - val_loss: 32890533888.0000\n",
            "Epoch 509/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 34467770368.0000 - val_loss: 32884690944.0000\n",
            "Epoch 510/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 34461720576.0000 - val_loss: 32878852096.0000\n",
            "Epoch 511/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 34455678976.0000 - val_loss: 32873009152.0000\n",
            "Epoch 512/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 34449637376.0000 - val_loss: 32867166208.0000\n",
            "Epoch 513/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 34443595776.0000 - val_loss: 32861325312.0000\n",
            "Epoch 514/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 34437550080.0000 - val_loss: 32855490560.0000\n",
            "Epoch 515/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 34431508480.0000 - val_loss: 32849651712.0000\n",
            "Epoch 516/1000\n",
            "1875/1875 [==============================] - 0s 6us/step - loss: 34425470976.0000 - val_loss: 32843816960.0000\n",
            "Epoch 517/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 34419429376.0000 - val_loss: 32837980160.0000\n",
            "Epoch 518/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 34413387776.0000 - val_loss: 32832143360.0000\n",
            "Epoch 519/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 34407350272.0000 - val_loss: 32826308608.0000\n",
            "Epoch 520/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 34401320960.0000 - val_loss: 32820480000.0000\n",
            "Epoch 521/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 34395283456.0000 - val_loss: 32814647296.0000\n",
            "Epoch 522/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 34389241856.0000 - val_loss: 32808818688.0000\n",
            "Epoch 523/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 34383212544.0000 - val_loss: 32802985984.0000\n",
            "Epoch 524/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 34377179136.0000 - val_loss: 32797161472.0000\n",
            "Epoch 525/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 34371149824.0000 - val_loss: 32791332864.0000\n",
            "Epoch 526/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 34365120512.0000 - val_loss: 32785504256.0000\n",
            "Epoch 527/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 34359093248.0000 - val_loss: 32779677696.0000\n",
            "Epoch 528/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 34353065984.0000 - val_loss: 32773857280.0000\n",
            "Epoch 529/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 34347034624.0000 - val_loss: 32768034816.0000\n",
            "Epoch 530/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 34341005312.0000 - val_loss: 32762210304.0000\n",
            "Epoch 531/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 34334984192.0000 - val_loss: 32756387840.0000\n",
            "Epoch 532/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 34328961024.0000 - val_loss: 32750567424.0000\n",
            "Epoch 533/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 34322935808.0000 - val_loss: 32744747008.0000\n",
            "Epoch 534/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 34316914688.0000 - val_loss: 32738930688.0000\n",
            "Epoch 535/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 34310891520.0000 - val_loss: 32733112320.0000\n",
            "Epoch 536/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 34304872448.0000 - val_loss: 32727296000.0000\n",
            "Epoch 537/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 34298851328.0000 - val_loss: 32721479680.0000\n",
            "Epoch 538/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 34292832256.0000 - val_loss: 32715665408.0000\n",
            "Epoch 539/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 34286815232.0000 - val_loss: 32709849088.0000\n",
            "Epoch 540/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 34280798208.0000 - val_loss: 32704038912.0000\n",
            "Epoch 541/1000\n",
            "1875/1875 [==============================] - 0s 5us/step - loss: 34274783232.0000 - val_loss: 32698226688.0000\n",
            "Epoch 542/1000\n",
            "1875/1875 [==============================] - 0s 5us/step - loss: 34268766208.0000 - val_loss: 32692418560.0000\n",
            "Epoch 543/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 34262755328.0000 - val_loss: 32686606336.0000\n",
            "Epoch 544/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 34256742400.0000 - val_loss: 32680798208.0000\n",
            "Epoch 545/1000\n",
            "1875/1875 [==============================] - 0s 5us/step - loss: 34250731520.0000 - val_loss: 32674992128.0000\n",
            "Epoch 546/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 34244720640.0000 - val_loss: 32669184000.0000\n",
            "Epoch 547/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 34238711808.0000 - val_loss: 32663382016.0000\n",
            "Epoch 548/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 34232705024.0000 - val_loss: 32657573888.0000\n",
            "Epoch 549/1000\n",
            "1875/1875 [==============================] - 0s 5us/step - loss: 34226694144.0000 - val_loss: 32651769856.0000\n",
            "Epoch 550/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 34220687360.0000 - val_loss: 32645967872.0000\n",
            "Epoch 551/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 34214682624.0000 - val_loss: 32640165888.0000\n",
            "Epoch 552/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 34208677888.0000 - val_loss: 32634365952.0000\n",
            "Epoch 553/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 34202677248.0000 - val_loss: 32628566016.0000\n",
            "Epoch 554/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 34196670464.0000 - val_loss: 32622766080.0000\n",
            "Epoch 555/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 34190667776.0000 - val_loss: 32616970240.0000\n",
            "Epoch 556/1000\n",
            "1875/1875 [==============================] - 0s 2us/step - loss: 34184669184.0000 - val_loss: 32611172352.0000\n",
            "Epoch 557/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 34178670592.0000 - val_loss: 32605376512.0000\n",
            "Epoch 558/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 34172669952.0000 - val_loss: 32599578624.0000\n",
            "Epoch 559/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 34166673408.0000 - val_loss: 32593788928.0000\n",
            "Epoch 560/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 34160674816.0000 - val_loss: 32587993088.0000\n",
            "Epoch 561/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 34154680320.0000 - val_loss: 32582203392.0000\n",
            "Epoch 562/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 34148683776.0000 - val_loss: 32576411648.0000\n",
            "Epoch 563/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 34142687232.0000 - val_loss: 32570621952.0000\n",
            "Epoch 564/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 34136696832.0000 - val_loss: 32564836352.0000\n",
            "Epoch 565/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 34130704384.0000 - val_loss: 32559044608.0000\n",
            "Epoch 566/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 34124713984.0000 - val_loss: 32553259008.0000\n",
            "Epoch 567/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 34118727680.0000 - val_loss: 32547473408.0000\n",
            "Epoch 568/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 34112737280.0000 - val_loss: 32541687808.0000\n",
            "Epoch 569/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 34106748928.0000 - val_loss: 32535904256.0000\n",
            "Epoch 570/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 34100760576.0000 - val_loss: 32530120704.0000\n",
            "Epoch 571/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 34094774272.0000 - val_loss: 32524339200.0000\n",
            "Epoch 572/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 34088787968.0000 - val_loss: 32518557696.0000\n",
            "Epoch 573/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 34082803712.0000 - val_loss: 32512778240.0000\n",
            "Epoch 574/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 34076823552.0000 - val_loss: 32506998784.0000\n",
            "Epoch 575/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 34070837248.0000 - val_loss: 32501223424.0000\n",
            "Epoch 576/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 34064859136.0000 - val_loss: 32495443968.0000\n",
            "Epoch 577/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 34058876928.0000 - val_loss: 32489668608.0000\n",
            "Epoch 578/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 34052898816.0000 - val_loss: 32483893248.0000\n",
            "Epoch 579/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 34046920704.0000 - val_loss: 32478119936.0000\n",
            "Epoch 580/1000\n",
            "1875/1875 [==============================] - 0s 5us/step - loss: 34040944640.0000 - val_loss: 32472346624.0000\n",
            "Epoch 581/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 34034966528.0000 - val_loss: 32466575360.0000\n",
            "Epoch 582/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 34028990464.0000 - val_loss: 32460802048.0000\n",
            "Epoch 583/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 34023016448.0000 - val_loss: 32455030784.0000\n",
            "Epoch 584/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 34017044480.0000 - val_loss: 32449263616.0000\n",
            "Epoch 585/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 34011070464.0000 - val_loss: 32443496448.0000\n",
            "Epoch 586/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 34005098496.0000 - val_loss: 32437727232.0000\n",
            "Epoch 587/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 33999128576.0000 - val_loss: 32431962112.0000\n",
            "Epoch 588/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 33993160704.0000 - val_loss: 32426194944.0000\n",
            "Epoch 589/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 33987192832.0000 - val_loss: 32420431872.0000\n",
            "Epoch 590/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 33981224960.0000 - val_loss: 32414670848.0000\n",
            "Epoch 591/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 33975259136.0000 - val_loss: 32408907776.0000\n",
            "Epoch 592/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 33969289216.0000 - val_loss: 32403144704.0000\n",
            "Epoch 593/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 33963325440.0000 - val_loss: 32397385728.0000\n",
            "Epoch 594/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 33957361664.0000 - val_loss: 32391628800.0000\n",
            "Epoch 595/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 33951397888.0000 - val_loss: 32385869824.0000\n",
            "Epoch 596/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 33945438208.0000 - val_loss: 32380110848.0000\n",
            "Epoch 597/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 33939480576.0000 - val_loss: 32374355968.0000\n",
            "Epoch 598/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 33933516800.0000 - val_loss: 32368599040.0000\n",
            "Epoch 599/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 33927559168.0000 - val_loss: 32362846208.0000\n",
            "Epoch 600/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 33921601536.0000 - val_loss: 32357093376.0000\n",
            "Epoch 601/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 33915643904.0000 - val_loss: 32351342592.0000\n",
            "Epoch 602/1000\n",
            "1875/1875 [==============================] - 0s 5us/step - loss: 33909688320.0000 - val_loss: 32345589760.0000\n",
            "Epoch 603/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 33903736832.0000 - val_loss: 32339836928.0000\n",
            "Epoch 604/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 33897781248.0000 - val_loss: 32334086144.0000\n",
            "Epoch 605/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 33891827712.0000 - val_loss: 32328337408.0000\n",
            "Epoch 606/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 33885876224.0000 - val_loss: 32322592768.0000\n",
            "Epoch 607/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 33879928832.0000 - val_loss: 32316844032.0000\n",
            "Epoch 608/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 33873975296.0000 - val_loss: 32311097344.0000\n",
            "Epoch 609/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 33868025856.0000 - val_loss: 32305356800.0000\n",
            "Epoch 610/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 33862076416.0000 - val_loss: 32299610112.0000\n",
            "Epoch 611/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 33856129024.0000 - val_loss: 32293871616.0000\n",
            "Epoch 612/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 33850183680.0000 - val_loss: 32288126976.0000\n",
            "Epoch 613/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 33844242432.0000 - val_loss: 32282388480.0000\n",
            "Epoch 614/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 33838292992.0000 - val_loss: 32276649984.0000\n",
            "Epoch 615/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 33832351744.0000 - val_loss: 32270907392.0000\n",
            "Epoch 616/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 33826410496.0000 - val_loss: 32265172992.0000\n",
            "Epoch 617/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 33820469248.0000 - val_loss: 32259436544.0000\n",
            "Epoch 618/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 33814528000.0000 - val_loss: 32253700096.0000\n",
            "Epoch 619/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 33808588800.0000 - val_loss: 32247963648.0000\n",
            "Epoch 620/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 33802647552.0000 - val_loss: 32242229248.0000\n",
            "Epoch 621/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 33796712448.0000 - val_loss: 32236494848.0000\n",
            "Epoch 622/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 33790777344.0000 - val_loss: 32230764544.0000\n",
            "Epoch 623/1000\n",
            "1875/1875 [==============================] - 0s 6us/step - loss: 33784842240.0000 - val_loss: 32225034240.0000\n",
            "Epoch 624/1000\n",
            "1875/1875 [==============================] - 0s 2us/step - loss: 33778907136.0000 - val_loss: 32219305984.0000\n",
            "Epoch 625/1000\n",
            "1875/1875 [==============================] - 0s 5us/step - loss: 33772974080.0000 - val_loss: 32213573632.0000\n",
            "Epoch 626/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 33767041024.0000 - val_loss: 32207847424.0000\n",
            "Epoch 627/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 33761110016.0000 - val_loss: 32202119168.0000\n",
            "Epoch 628/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 33755179008.0000 - val_loss: 32196395008.0000\n",
            "Epoch 629/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 33749250048.0000 - val_loss: 32190670848.0000\n",
            "Epoch 630/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 33743319040.0000 - val_loss: 32184944640.0000\n",
            "Epoch 631/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 33737390080.0000 - val_loss: 32179222528.0000\n",
            "Epoch 632/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 33731467264.0000 - val_loss: 32173500416.0000\n",
            "Epoch 633/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 33725536256.0000 - val_loss: 32167778304.0000\n",
            "Epoch 634/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 33719615488.0000 - val_loss: 32162058240.0000\n",
            "Epoch 635/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 33713690624.0000 - val_loss: 32156342272.0000\n",
            "Epoch 636/1000\n",
            "1875/1875 [==============================] - 0s 2us/step - loss: 33707763712.0000 - val_loss: 32150622208.0000\n",
            "Epoch 637/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 33701847040.0000 - val_loss: 32144904192.0000\n",
            "Epoch 638/1000\n",
            "1875/1875 [==============================] - 0s 7us/step - loss: 33695924224.0000 - val_loss: 32139188224.0000\n",
            "Epoch 639/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 33690005504.0000 - val_loss: 32133470208.0000\n",
            "Epoch 640/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 33684086784.0000 - val_loss: 32127758336.0000\n",
            "Epoch 641/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 33678166016.0000 - val_loss: 32122044416.0000\n",
            "Epoch 642/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 33672251392.0000 - val_loss: 32116330496.0000\n",
            "Epoch 643/1000\n",
            "1875/1875 [==============================] - 0s 7us/step - loss: 33666334720.0000 - val_loss: 32110620672.0000\n",
            "Epoch 644/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 33660420096.0000 - val_loss: 32104910848.0000\n",
            "Epoch 645/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 33654503424.0000 - val_loss: 32099201024.0000\n",
            "Epoch 646/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 33648590848.0000 - val_loss: 32093495296.0000\n",
            "Epoch 647/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 33642680320.0000 - val_loss: 32087787520.0000\n",
            "Epoch 648/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 33636765696.0000 - val_loss: 32082081792.0000\n",
            "Epoch 649/1000\n",
            "1875/1875 [==============================] - 0s 2us/step - loss: 33630857216.0000 - val_loss: 32076371968.0000\n",
            "Epoch 650/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 33624952832.0000 - val_loss: 32070668288.0000\n",
            "Epoch 651/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 33619038208.0000 - val_loss: 32064962560.0000\n",
            "Epoch 652/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 33613133824.0000 - val_loss: 32059262976.0000\n",
            "Epoch 653/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 33607227392.0000 - val_loss: 32053561344.0000\n",
            "Epoch 654/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 33601320960.0000 - val_loss: 32047857664.0000\n",
            "Epoch 655/1000\n",
            "1875/1875 [==============================] - 0s 5us/step - loss: 33595418624.0000 - val_loss: 32042160128.0000\n",
            "Epoch 656/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 33589510144.0000 - val_loss: 32036460544.0000\n",
            "Epoch 657/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 33583611904.0000 - val_loss: 32030763008.0000\n",
            "Epoch 658/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 33577709568.0000 - val_loss: 32025065472.0000\n",
            "Epoch 659/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 33571809280.0000 - val_loss: 32019369984.0000\n",
            "Epoch 660/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 33565906944.0000 - val_loss: 32013676544.0000\n",
            "Epoch 661/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 33560008704.0000 - val_loss: 32007981056.0000\n",
            "Epoch 662/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 33554112512.0000 - val_loss: 32002289664.0000\n",
            "Epoch 663/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 33548218368.0000 - val_loss: 31996596224.0000\n",
            "Epoch 664/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 33542318080.0000 - val_loss: 31990906880.0000\n",
            "Epoch 665/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 33536421888.0000 - val_loss: 31985219584.0000\n",
            "Epoch 666/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 33530527744.0000 - val_loss: 31979528192.0000\n",
            "Epoch 667/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 33524637696.0000 - val_loss: 31973836800.0000\n",
            "Epoch 668/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 33518745600.0000 - val_loss: 31968153600.0000\n",
            "Epoch 669/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 33512853504.0000 - val_loss: 31962466304.0000\n",
            "Epoch 670/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 33506963456.0000 - val_loss: 31956779008.0000\n",
            "Epoch 671/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 33501071360.0000 - val_loss: 31951095808.0000\n",
            "Epoch 672/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 33495185408.0000 - val_loss: 31945410560.0000\n",
            "Epoch 673/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 33489301504.0000 - val_loss: 31939727360.0000\n",
            "Epoch 674/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 33483415552.0000 - val_loss: 31934048256.0000\n",
            "Epoch 675/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 33477529600.0000 - val_loss: 31928367104.0000\n",
            "Epoch 676/1000\n",
            "1875/1875 [==============================] - 0s 5us/step - loss: 33471643648.0000 - val_loss: 31922692096.0000\n",
            "Epoch 677/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 33465761792.0000 - val_loss: 31917012992.0000\n",
            "Epoch 678/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 33459877888.0000 - val_loss: 31911333888.0000\n",
            "Epoch 679/1000\n",
            "1875/1875 [==============================] - 0s 6us/step - loss: 33453993984.0000 - val_loss: 31905658880.0000\n",
            "Epoch 680/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 33448116224.0000 - val_loss: 31899979776.0000\n",
            "Epoch 681/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 33442236416.0000 - val_loss: 31894306816.0000\n",
            "Epoch 682/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 33436358656.0000 - val_loss: 31888637952.0000\n",
            "Epoch 683/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 33430476800.0000 - val_loss: 31882962944.0000\n",
            "Epoch 684/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 33424603136.0000 - val_loss: 31877289984.0000\n",
            "Epoch 685/1000\n",
            "1875/1875 [==============================] - 0s 5us/step - loss: 33418727424.0000 - val_loss: 31871621120.0000\n",
            "Epoch 686/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 33412849664.0000 - val_loss: 31865950208.0000\n",
            "Epoch 687/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 33406978048.0000 - val_loss: 31860283392.0000\n",
            "Epoch 688/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 33401106432.0000 - val_loss: 31854616576.0000\n",
            "Epoch 689/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 33395232768.0000 - val_loss: 31848945664.0000\n",
            "Epoch 690/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 33389365248.0000 - val_loss: 31843282944.0000\n",
            "Epoch 691/1000\n",
            "1875/1875 [==============================] - 0s 7us/step - loss: 33383493632.0000 - val_loss: 31837616128.0000\n",
            "Epoch 692/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 33377622016.0000 - val_loss: 31831955456.0000\n",
            "Epoch 693/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 33371756544.0000 - val_loss: 31826288640.0000\n",
            "Epoch 694/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 33365889024.0000 - val_loss: 31820627968.0000\n",
            "Epoch 695/1000\n",
            "1875/1875 [==============================] - 0s 5us/step - loss: 33360023552.0000 - val_loss: 31814965248.0000\n",
            "Epoch 696/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 33354156032.0000 - val_loss: 31809306624.0000\n",
            "Epoch 697/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 33348290560.0000 - val_loss: 31803645952.0000\n",
            "Epoch 698/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 33342429184.0000 - val_loss: 31797989376.0000\n",
            "Epoch 699/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 33336567808.0000 - val_loss: 31792330752.0000\n",
            "Epoch 700/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 33330706432.0000 - val_loss: 31786676224.0000\n",
            "Epoch 701/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 33324843008.0000 - val_loss: 31781019648.0000\n",
            "Epoch 702/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 33318985728.0000 - val_loss: 31775365120.0000\n",
            "Epoch 703/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 33313126400.0000 - val_loss: 31769710592.0000\n",
            "Epoch 704/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 33307269120.0000 - val_loss: 31764060160.0000\n",
            "Epoch 705/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 33301415936.0000 - val_loss: 31758407680.0000\n",
            "Epoch 706/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 33295556608.0000 - val_loss: 31752759296.0000\n",
            "Epoch 707/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 33289705472.0000 - val_loss: 31747108864.0000\n",
            "Epoch 708/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 33283848192.0000 - val_loss: 31741462528.0000\n",
            "Epoch 709/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 33277997056.0000 - val_loss: 31735812096.0000\n",
            "Epoch 710/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 33272145920.0000 - val_loss: 31730167808.0000\n",
            "Epoch 711/1000\n",
            "1875/1875 [==============================] - 0s 5us/step - loss: 33266294784.0000 - val_loss: 31724521472.0000\n",
            "Epoch 712/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 33260443648.0000 - val_loss: 31718877184.0000\n",
            "Epoch 713/1000\n",
            "1875/1875 [==============================] - 0s 6us/step - loss: 33254594560.0000 - val_loss: 31713230848.0000\n",
            "Epoch 714/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 33248743424.0000 - val_loss: 31707592704.0000\n",
            "Epoch 715/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 33242898432.0000 - val_loss: 31701948416.0000\n",
            "Epoch 716/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 33237053440.0000 - val_loss: 31696306176.0000\n",
            "Epoch 717/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 33231210496.0000 - val_loss: 31690668032.0000\n",
            "Epoch 718/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 33225363456.0000 - val_loss: 31685029888.0000\n",
            "Epoch 719/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 33219522560.0000 - val_loss: 31679391744.0000\n",
            "Epoch 720/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 33213675520.0000 - val_loss: 31673753600.0000\n",
            "Epoch 721/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 33207836672.0000 - val_loss: 31668119552.0000\n",
            "Epoch 722/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 33201993728.0000 - val_loss: 31662481408.0000\n",
            "Epoch 723/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 33196156928.0000 - val_loss: 31656849408.0000\n",
            "Epoch 724/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 33190320128.0000 - val_loss: 31651217408.0000\n",
            "Epoch 725/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 33184479232.0000 - val_loss: 31645583360.0000\n",
            "Epoch 726/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 33178646528.0000 - val_loss: 31639951360.0000\n",
            "Epoch 727/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 33172807680.0000 - val_loss: 31634321408.0000\n",
            "Epoch 728/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 33166974976.0000 - val_loss: 31628691456.0000\n",
            "Epoch 729/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 33161144320.0000 - val_loss: 31623063552.0000\n",
            "Epoch 730/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 33155309568.0000 - val_loss: 31617437696.0000\n",
            "Epoch 731/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 33149476864.0000 - val_loss: 31611809792.0000\n",
            "Epoch 732/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 33143646208.0000 - val_loss: 31606185984.0000\n",
            "Epoch 733/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 33137813504.0000 - val_loss: 31600560128.0000\n",
            "Epoch 734/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 33131986944.0000 - val_loss: 31594936320.0000\n",
            "Epoch 735/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 33126156288.0000 - val_loss: 31589316608.0000\n",
            "Epoch 736/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 33120331776.0000 - val_loss: 31583692800.0000\n",
            "Epoch 737/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 33114507264.0000 - val_loss: 31578071040.0000\n",
            "Epoch 738/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 33108680704.0000 - val_loss: 31572453376.0000\n",
            "Epoch 739/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 33102854144.0000 - val_loss: 31566833664.0000\n",
            "Epoch 740/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 33097033728.0000 - val_loss: 31561213952.0000\n",
            "Epoch 741/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 33091211264.0000 - val_loss: 31555600384.0000\n",
            "Epoch 742/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 33085390848.0000 - val_loss: 31549982720.0000\n",
            "Epoch 743/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 33079568384.0000 - val_loss: 31544367104.0000\n",
            "Epoch 744/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 33073745920.0000 - val_loss: 31538753536.0000\n",
            "Epoch 745/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 33067927552.0000 - val_loss: 31533142016.0000\n",
            "Epoch 746/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 33062109184.0000 - val_loss: 31527528448.0000\n",
            "Epoch 747/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 33056296960.0000 - val_loss: 31521918976.0000\n",
            "Epoch 748/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 33050478592.0000 - val_loss: 31516309504.0000\n",
            "Epoch 749/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 33044664320.0000 - val_loss: 31510700032.0000\n",
            "Epoch 750/1000\n",
            "1875/1875 [==============================] - 0s 5us/step - loss: 33038850048.0000 - val_loss: 31505086464.0000\n",
            "Epoch 751/1000\n",
            "1875/1875 [==============================] - 0s 6us/step - loss: 33033037824.0000 - val_loss: 31499481088.0000\n",
            "Epoch 752/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 33027225600.0000 - val_loss: 31493877760.0000\n",
            "Epoch 753/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 33021415424.0000 - val_loss: 31488270336.0000\n",
            "Epoch 754/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 33015607296.0000 - val_loss: 31482667008.0000\n",
            "Epoch 755/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 33009797120.0000 - val_loss: 31477063680.0000\n",
            "Epoch 756/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 33003986944.0000 - val_loss: 31471462400.0000\n",
            "Epoch 757/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 32998182912.0000 - val_loss: 31465857024.0000\n",
            "Epoch 758/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 32992376832.0000 - val_loss: 31460257792.0000\n",
            "Epoch 759/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 32986568704.0000 - val_loss: 31454660608.0000\n",
            "Epoch 760/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 32980764672.0000 - val_loss: 31449059328.0000\n",
            "Epoch 761/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 32974960640.0000 - val_loss: 31443462144.0000\n",
            "Epoch 762/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 32969158656.0000 - val_loss: 31437867008.0000\n",
            "Epoch 763/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 32963354624.0000 - val_loss: 31432265728.0000\n",
            "Epoch 764/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 32957556736.0000 - val_loss: 31426674688.0000\n",
            "Epoch 765/1000\n",
            "1875/1875 [==============================] - 0s 2us/step - loss: 32951756800.0000 - val_loss: 31421077504.0000\n",
            "Epoch 766/1000\n",
            "1875/1875 [==============================] - 0s 5us/step - loss: 32945958912.0000 - val_loss: 31415486464.0000\n",
            "Epoch 767/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 32940156928.0000 - val_loss: 31409895424.0000\n",
            "Epoch 768/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 32934361088.0000 - val_loss: 31404304384.0000\n",
            "Epoch 769/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 32928565248.0000 - val_loss: 31398713344.0000\n",
            "Epoch 770/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 32922771456.0000 - val_loss: 31393126400.0000\n",
            "Epoch 771/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 32916979712.0000 - val_loss: 31387537408.0000\n",
            "Epoch 772/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 32911183872.0000 - val_loss: 31381950464.0000\n",
            "Epoch 773/1000\n",
            "1875/1875 [==============================] - 0s 2us/step - loss: 32905390080.0000 - val_loss: 31376361472.0000\n",
            "Epoch 774/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 32899602432.0000 - val_loss: 31370778624.0000\n",
            "Epoch 775/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 32893812736.0000 - val_loss: 31365195776.0000\n",
            "Epoch 776/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 32888020992.0000 - val_loss: 31359608832.0000\n",
            "Epoch 777/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 32882233344.0000 - val_loss: 31354028032.0000\n",
            "Epoch 778/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 32876449792.0000 - val_loss: 31348447232.0000\n",
            "Epoch 779/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 32870662144.0000 - val_loss: 31342866432.0000\n",
            "Epoch 780/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 32864874496.0000 - val_loss: 31337283584.0000\n",
            "Epoch 781/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 32859092992.0000 - val_loss: 31331708928.0000\n",
            "Epoch 782/1000\n",
            "1875/1875 [==============================] - 0s 5us/step - loss: 32853305344.0000 - val_loss: 31326128128.0000\n",
            "Epoch 783/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 32847519744.0000 - val_loss: 31320553472.0000\n",
            "Epoch 784/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 32841740288.0000 - val_loss: 31314976768.0000\n",
            "Epoch 785/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 32835962880.0000 - val_loss: 31309400064.0000\n",
            "Epoch 786/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 32830181376.0000 - val_loss: 31303827456.0000\n",
            "Epoch 787/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 32824403968.0000 - val_loss: 31298254848.0000\n",
            "Epoch 788/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 32818624512.0000 - val_loss: 31292682240.0000\n",
            "Epoch 789/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 32812847104.0000 - val_loss: 31287111680.0000\n",
            "Epoch 790/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 32807071744.0000 - val_loss: 31281537024.0000\n",
            "Epoch 791/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 32801296384.0000 - val_loss: 31275970560.0000\n",
            "Epoch 792/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 32795521024.0000 - val_loss: 31270404096.0000\n",
            "Epoch 793/1000\n",
            "1875/1875 [==============================] - 0s 5us/step - loss: 32789749760.0000 - val_loss: 31264835584.0000\n",
            "Epoch 794/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 32783978496.0000 - val_loss: 31259269120.0000\n",
            "Epoch 795/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 32778205184.0000 - val_loss: 31253706752.0000\n",
            "Epoch 796/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 32772431872.0000 - val_loss: 31248140288.0000\n",
            "Epoch 797/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 32766662656.0000 - val_loss: 31242573824.0000\n",
            "Epoch 798/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 32760897536.0000 - val_loss: 31237013504.0000\n",
            "Epoch 799/1000\n",
            "1875/1875 [==============================] - 0s 2us/step - loss: 32755130368.0000 - val_loss: 31231451136.0000\n",
            "Epoch 800/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 32749363200.0000 - val_loss: 31225888768.0000\n",
            "Epoch 801/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 32743598080.0000 - val_loss: 31220328448.0000\n",
            "Epoch 802/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 32737830912.0000 - val_loss: 31214772224.0000\n",
            "Epoch 803/1000\n",
            "1875/1875 [==============================] - 0s 2us/step - loss: 32732067840.0000 - val_loss: 31209211904.0000\n",
            "Epoch 804/1000\n",
            "1875/1875 [==============================] - 0s 2us/step - loss: 32726304768.0000 - val_loss: 31203655680.0000\n",
            "Epoch 805/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 32720541696.0000 - val_loss: 31198101504.0000\n",
            "Epoch 806/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 32714784768.0000 - val_loss: 31192545280.0000\n",
            "Epoch 807/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 32709019648.0000 - val_loss: 31186993152.0000\n",
            "Epoch 808/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 32703258624.0000 - val_loss: 31181434880.0000\n",
            "Epoch 809/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 32697503744.0000 - val_loss: 31175888896.0000\n",
            "Epoch 810/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 32691746816.0000 - val_loss: 31170334720.0000\n",
            "Epoch 811/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 32685989888.0000 - val_loss: 31164782592.0000\n",
            "Epoch 812/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 32680230912.0000 - val_loss: 31159234560.0000\n",
            "Epoch 813/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 32674480128.0000 - val_loss: 31153684480.0000\n",
            "Epoch 814/1000\n",
            "1875/1875 [==============================] - 0s 5us/step - loss: 32668725248.0000 - val_loss: 31148138496.0000\n",
            "Epoch 815/1000\n",
            "1875/1875 [==============================] - 0s 5us/step - loss: 32662974464.0000 - val_loss: 31142592512.0000\n",
            "Epoch 816/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 32657221632.0000 - val_loss: 31137048576.0000\n",
            "Epoch 817/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 32651470848.0000 - val_loss: 31131506688.0000\n",
            "Epoch 818/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 32645720064.0000 - val_loss: 31125960704.0000\n",
            "Epoch 819/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 32639971328.0000 - val_loss: 31120416768.0000\n",
            "Epoch 820/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 32634224640.0000 - val_loss: 31114872832.0000\n",
            "Epoch 821/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 32628480000.0000 - val_loss: 31109330944.0000\n",
            "Epoch 822/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 32622731264.0000 - val_loss: 31103793152.0000\n",
            "Epoch 823/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 32616984576.0000 - val_loss: 31098255360.0000\n",
            "Epoch 824/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 32611244032.0000 - val_loss: 31092715520.0000\n",
            "Epoch 825/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 32605495296.0000 - val_loss: 31087177728.0000\n",
            "Epoch 826/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 32599756800.0000 - val_loss: 31081644032.0000\n",
            "Epoch 827/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 32594014208.0000 - val_loss: 31076104192.0000\n",
            "Epoch 828/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 32588273664.0000 - val_loss: 31070572544.0000\n",
            "Epoch 829/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 32582535168.0000 - val_loss: 31065038848.0000\n",
            "Epoch 830/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 32576794624.0000 - val_loss: 31059507200.0000\n",
            "Epoch 831/1000\n",
            "1875/1875 [==============================] - 0s 2us/step - loss: 32571056128.0000 - val_loss: 31053971456.0000\n",
            "Epoch 832/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 32565319680.0000 - val_loss: 31048443904.0000\n",
            "Epoch 833/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 32559587328.0000 - val_loss: 31042916352.0000\n",
            "Epoch 834/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 32553850880.0000 - val_loss: 31037388800.0000\n",
            "Epoch 835/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 32548114432.0000 - val_loss: 31031857152.0000\n",
            "Epoch 836/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 32542384128.0000 - val_loss: 31026331648.0000\n",
            "Epoch 837/1000\n",
            "1875/1875 [==============================] - 0s 5us/step - loss: 32536649728.0000 - val_loss: 31020804096.0000\n",
            "Epoch 838/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 32530919424.0000 - val_loss: 31015276544.0000\n",
            "Epoch 839/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 32525189120.0000 - val_loss: 31009757184.0000\n",
            "Epoch 840/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 32519458816.0000 - val_loss: 31004235776.0000\n",
            "Epoch 841/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 32513734656.0000 - val_loss: 30998710272.0000\n",
            "Epoch 842/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 32508000256.0000 - val_loss: 30993190912.0000\n",
            "Epoch 843/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 32502276096.0000 - val_loss: 30987667456.0000\n",
            "Epoch 844/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 32496553984.0000 - val_loss: 30982152192.0000\n",
            "Epoch 845/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 32490827776.0000 - val_loss: 30976634880.0000\n",
            "Epoch 846/1000\n",
            "1875/1875 [==============================] - 0s 2us/step - loss: 32485105664.0000 - val_loss: 30971113472.0000\n",
            "Epoch 847/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 32479379456.0000 - val_loss: 30965598208.0000\n",
            "Epoch 848/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 32473659392.0000 - val_loss: 30960082944.0000\n",
            "Epoch 849/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 32467937280.0000 - val_loss: 30954567680.0000\n",
            "Epoch 850/1000\n",
            "1875/1875 [==============================] - 0s 5us/step - loss: 32462215168.0000 - val_loss: 30949058560.0000\n",
            "Epoch 851/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 32456495104.0000 - val_loss: 30943543296.0000\n",
            "Epoch 852/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 32450781184.0000 - val_loss: 30938030080.0000\n",
            "Epoch 853/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 32445065216.0000 - val_loss: 30932518912.0000\n",
            "Epoch 854/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 32439349248.0000 - val_loss: 30927007744.0000\n",
            "Epoch 855/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 32433631232.0000 - val_loss: 30921500672.0000\n",
            "Epoch 856/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 32427915264.0000 - val_loss: 30915993600.0000\n",
            "Epoch 857/1000\n",
            "1875/1875 [==============================] - 0s 2us/step - loss: 32422205440.0000 - val_loss: 30910482432.0000\n",
            "Epoch 858/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 32416491520.0000 - val_loss: 30904977408.0000\n",
            "Epoch 859/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 32410779648.0000 - val_loss: 30899472384.0000\n",
            "Epoch 860/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 32405069824.0000 - val_loss: 30893967360.0000\n",
            "Epoch 861/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 32399357952.0000 - val_loss: 30888466432.0000\n",
            "Epoch 862/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 32393650176.0000 - val_loss: 30882963456.0000\n",
            "Epoch 863/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 32387940352.0000 - val_loss: 30877464576.0000\n",
            "Epoch 864/1000\n",
            "1875/1875 [==============================] - 0s 5us/step - loss: 32382232576.0000 - val_loss: 30871961600.0000\n",
            "Epoch 865/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 32376528896.0000 - val_loss: 30866462720.0000\n",
            "Epoch 866/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 32370823168.0000 - val_loss: 30860963840.0000\n",
            "Epoch 867/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 32365119488.0000 - val_loss: 30855464960.0000\n",
            "Epoch 868/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 32359415808.0000 - val_loss: 30849966080.0000\n",
            "Epoch 869/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 32353714176.0000 - val_loss: 30844473344.0000\n",
            "Epoch 870/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 32348010496.0000 - val_loss: 30838978560.0000\n",
            "Epoch 871/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 32342312960.0000 - val_loss: 30833481728.0000\n",
            "Epoch 872/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 32336611328.0000 - val_loss: 30827991040.0000\n",
            "Epoch 873/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 32330911744.0000 - val_loss: 30822498304.0000\n",
            "Epoch 874/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 32325214208.0000 - val_loss: 30817007616.0000\n",
            "Epoch 875/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 32319516672.0000 - val_loss: 30811518976.0000\n",
            "Epoch 876/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 32313821184.0000 - val_loss: 30806026240.0000\n",
            "Epoch 877/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 32308125696.0000 - val_loss: 30800537600.0000\n",
            "Epoch 878/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 32302434304.0000 - val_loss: 30795053056.0000\n",
            "Epoch 879/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 32296736768.0000 - val_loss: 30789564416.0000\n",
            "Epoch 880/1000\n",
            "1875/1875 [==============================] - 0s 5us/step - loss: 32291047424.0000 - val_loss: 30784077824.0000\n",
            "Epoch 881/1000\n",
            "1875/1875 [==============================] - 0s 5us/step - loss: 32285358080.0000 - val_loss: 30778593280.0000\n",
            "Epoch 882/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 32279664640.0000 - val_loss: 30773112832.0000\n",
            "Epoch 883/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 32273977344.0000 - val_loss: 30767628288.0000\n",
            "Epoch 884/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 32268288000.0000 - val_loss: 30762145792.0000\n",
            "Epoch 885/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 32262600704.0000 - val_loss: 30756667392.0000\n",
            "Epoch 886/1000\n",
            "1875/1875 [==============================] - 0s 2us/step - loss: 32256915456.0000 - val_loss: 30751182848.0000\n",
            "Epoch 887/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 32251230208.0000 - val_loss: 30745708544.0000\n",
            "Epoch 888/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 32245540864.0000 - val_loss: 30740228096.0000\n",
            "Epoch 889/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 32239861760.0000 - val_loss: 30734751744.0000\n",
            "Epoch 890/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 32234176512.0000 - val_loss: 30729273344.0000\n",
            "Epoch 891/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 32228493312.0000 - val_loss: 30723796992.0000\n",
            "Epoch 892/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 32222810112.0000 - val_loss: 30718324736.0000\n",
            "Epoch 893/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 32217131008.0000 - val_loss: 30712850432.0000\n",
            "Epoch 894/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 32211451904.0000 - val_loss: 30707376128.0000\n",
            "Epoch 895/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 32205774848.0000 - val_loss: 30701907968.0000\n",
            "Epoch 896/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 32200093696.0000 - val_loss: 30696433664.0000\n",
            "Epoch 897/1000\n",
            "1875/1875 [==============================] - 0s 6us/step - loss: 32194420736.0000 - val_loss: 30690967552.0000\n",
            "Epoch 898/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 32188743680.0000 - val_loss: 30685497344.0000\n",
            "Epoch 899/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 32183070720.0000 - val_loss: 30680027136.0000\n",
            "Epoch 900/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 32177397760.0000 - val_loss: 30674561024.0000\n",
            "Epoch 901/1000\n",
            "1875/1875 [==============================] - 0s 5us/step - loss: 32171724800.0000 - val_loss: 30669096960.0000\n",
            "Epoch 902/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 32166049792.0000 - val_loss: 30663630848.0000\n",
            "Epoch 903/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 32160380928.0000 - val_loss: 30658166784.0000\n",
            "Epoch 904/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 32154712064.0000 - val_loss: 30652704768.0000\n",
            "Epoch 905/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 32149043200.0000 - val_loss: 30647238656.0000\n",
            "Epoch 906/1000\n",
            "1875/1875 [==============================] - 0s 2us/step - loss: 32143374336.0000 - val_loss: 30641780736.0000\n",
            "Epoch 907/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 32137707520.0000 - val_loss: 30636320768.0000\n",
            "Epoch 908/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 32132038656.0000 - val_loss: 30630860800.0000\n",
            "Epoch 909/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 32126375936.0000 - val_loss: 30625400832.0000\n",
            "Epoch 910/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 32120709120.0000 - val_loss: 30619944960.0000\n",
            "Epoch 911/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 32115048448.0000 - val_loss: 30614487040.0000\n",
            "Epoch 912/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 32109383680.0000 - val_loss: 30609031168.0000\n",
            "Epoch 913/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 32103723008.0000 - val_loss: 30603575296.0000\n",
            "Epoch 914/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 32098060288.0000 - val_loss: 30598121472.0000\n",
            "Epoch 915/1000\n",
            "1875/1875 [==============================] - 0s 2us/step - loss: 32092397568.0000 - val_loss: 30592667648.0000\n",
            "Epoch 916/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 32086743040.0000 - val_loss: 30587215872.0000\n",
            "Epoch 917/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 32081084416.0000 - val_loss: 30581766144.0000\n",
            "Epoch 918/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 32075425792.0000 - val_loss: 30576314368.0000\n",
            "Epoch 919/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 32069769216.0000 - val_loss: 30570864640.0000\n",
            "Epoch 920/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 32064114688.0000 - val_loss: 30565419008.0000\n",
            "Epoch 921/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 32058458112.0000 - val_loss: 30559969280.0000\n",
            "Epoch 922/1000\n",
            "1875/1875 [==============================] - 0s 6us/step - loss: 32052807680.0000 - val_loss: 30554525696.0000\n",
            "Epoch 923/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 32047153152.0000 - val_loss: 30549075968.0000\n",
            "Epoch 924/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 32041502720.0000 - val_loss: 30543632384.0000\n",
            "Epoch 925/1000\n",
            "1875/1875 [==============================] - 0s 2us/step - loss: 32035852288.0000 - val_loss: 30538188800.0000\n",
            "Epoch 926/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 32030201856.0000 - val_loss: 30532745216.0000\n",
            "Epoch 927/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 32024553472.0000 - val_loss: 30527305728.0000\n",
            "Epoch 928/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 32018905088.0000 - val_loss: 30521862144.0000\n",
            "Epoch 929/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 32013256704.0000 - val_loss: 30516422656.0000\n",
            "Epoch 930/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 32007608320.0000 - val_loss: 30510981120.0000\n",
            "Epoch 931/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 32001968128.0000 - val_loss: 30505543680.0000\n",
            "Epoch 932/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 31996323840.0000 - val_loss: 30500106240.0000\n",
            "Epoch 933/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 31990679552.0000 - val_loss: 30494670848.0000\n",
            "Epoch 934/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 31985035264.0000 - val_loss: 30489235456.0000\n",
            "Epoch 935/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 31979395072.0000 - val_loss: 30483802112.0000\n",
            "Epoch 936/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 31973754880.0000 - val_loss: 30478368768.0000\n",
            "Epoch 937/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 31968116736.0000 - val_loss: 30472933376.0000\n",
            "Epoch 938/1000\n",
            "1875/1875 [==============================] - 0s 2us/step - loss: 31962476544.0000 - val_loss: 30467502080.0000\n",
            "Epoch 939/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 31956838400.0000 - val_loss: 30462072832.0000\n",
            "Epoch 940/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 31951200256.0000 - val_loss: 30456641536.0000\n",
            "Epoch 941/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 31945564160.0000 - val_loss: 30451212288.0000\n",
            "Epoch 942/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 31939930112.0000 - val_loss: 30445785088.0000\n",
            "Epoch 943/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 31934291968.0000 - val_loss: 30440357888.0000\n",
            "Epoch 944/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 31928662016.0000 - val_loss: 30434932736.0000\n",
            "Epoch 945/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 31923027968.0000 - val_loss: 30429505536.0000\n",
            "Epoch 946/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 31917395968.0000 - val_loss: 30424082432.0000\n",
            "Epoch 947/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 31911768064.0000 - val_loss: 30418657280.0000\n",
            "Epoch 948/1000\n",
            "1875/1875 [==============================] - 0s 7us/step - loss: 31906138112.0000 - val_loss: 30413236224.0000\n",
            "Epoch 949/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 31900510208.0000 - val_loss: 30407815168.0000\n",
            "Epoch 950/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 31894880256.0000 - val_loss: 30402390016.0000\n",
            "Epoch 951/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 31889252352.0000 - val_loss: 30396975104.0000\n",
            "Epoch 952/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 31883626496.0000 - val_loss: 30391554048.0000\n",
            "Epoch 953/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 31878002688.0000 - val_loss: 30386139136.0000\n",
            "Epoch 954/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 31872376832.0000 - val_loss: 30380720128.0000\n",
            "Epoch 955/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 31866750976.0000 - val_loss: 30375301120.0000\n",
            "Epoch 956/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 31861129216.0000 - val_loss: 30369888256.0000\n",
            "Epoch 957/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 31855513600.0000 - val_loss: 30364471296.0000\n",
            "Epoch 958/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 31849889792.0000 - val_loss: 30359058432.0000\n",
            "Epoch 959/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 31844265984.0000 - val_loss: 30353647616.0000\n",
            "Epoch 960/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 31838650368.0000 - val_loss: 30348236800.0000\n",
            "Epoch 961/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 31833032704.0000 - val_loss: 30342823936.0000\n",
            "Epoch 962/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 31827417088.0000 - val_loss: 30337417216.0000\n",
            "Epoch 963/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 31821801472.0000 - val_loss: 30332010496.0000\n",
            "Epoch 964/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 31816185856.0000 - val_loss: 30326597632.0000\n",
            "Epoch 965/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 31810572288.0000 - val_loss: 30321192960.0000\n",
            "Epoch 966/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 31804960768.0000 - val_loss: 30315786240.0000\n",
            "Epoch 967/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 31799345152.0000 - val_loss: 30310381568.0000\n",
            "Epoch 968/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 31793731584.0000 - val_loss: 30304978944.0000\n",
            "Epoch 969/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 31788122112.0000 - val_loss: 30299574272.0000\n",
            "Epoch 970/1000\n",
            "1875/1875 [==============================] - 0s 2us/step - loss: 31782512640.0000 - val_loss: 30294171648.0000\n",
            "Epoch 971/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 31776905216.0000 - val_loss: 30288771072.0000\n",
            "Epoch 972/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 31771297792.0000 - val_loss: 30283368448.0000\n",
            "Epoch 973/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 31765690368.0000 - val_loss: 30277967872.0000\n",
            "Epoch 974/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 31760084992.0000 - val_loss: 30272573440.0000\n",
            "Epoch 975/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 31754477568.0000 - val_loss: 30267172864.0000\n",
            "Epoch 976/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 31748872192.0000 - val_loss: 30261774336.0000\n",
            "Epoch 977/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 31743270912.0000 - val_loss: 30256377856.0000\n",
            "Epoch 978/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 31737667584.0000 - val_loss: 30250985472.0000\n",
            "Epoch 979/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 31732066304.0000 - val_loss: 30245588992.0000\n",
            "Epoch 980/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 31726469120.0000 - val_loss: 30240198656.0000\n",
            "Epoch 981/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 31720867840.0000 - val_loss: 30234806272.0000\n",
            "Epoch 982/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 31715268608.0000 - val_loss: 30229413888.0000\n",
            "Epoch 983/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 31709671424.0000 - val_loss: 30224025600.0000\n",
            "Epoch 984/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 31704070144.0000 - val_loss: 30218635264.0000\n",
            "Epoch 985/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 31698479104.0000 - val_loss: 30213249024.0000\n",
            "Epoch 986/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 31692881920.0000 - val_loss: 30207858688.0000\n",
            "Epoch 987/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 31687288832.0000 - val_loss: 30202470400.0000\n",
            "Epoch 988/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 31681693696.0000 - val_loss: 30197086208.0000\n",
            "Epoch 989/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 31676102656.0000 - val_loss: 30191699968.0000\n",
            "Epoch 990/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 31670507520.0000 - val_loss: 30186315776.0000\n",
            "Epoch 991/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 31664918528.0000 - val_loss: 30180933632.0000\n",
            "Epoch 992/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 31659329536.0000 - val_loss: 30175549440.0000\n",
            "Epoch 993/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 31653740544.0000 - val_loss: 30170171392.0000\n",
            "Epoch 994/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 31648155648.0000 - val_loss: 30164791296.0000\n",
            "Epoch 995/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 31642564608.0000 - val_loss: 30159409152.0000\n",
            "Epoch 996/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 31636983808.0000 - val_loss: 30154029056.0000\n",
            "Epoch 997/1000\n",
            "1875/1875 [==============================] - 0s 3us/step - loss: 31631390720.0000 - val_loss: 30148653056.0000\n",
            "Epoch 998/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 31625811968.0000 - val_loss: 30143277056.0000\n",
            "Epoch 999/1000\n",
            "1875/1875 [==============================] - 0s 2us/step - loss: 31620227072.0000 - val_loss: 30137899008.0000\n",
            "Epoch 1000/1000\n",
            "1875/1875 [==============================] - 0s 4us/step - loss: 31614646272.0000 - val_loss: 30132525056.0000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f6a180bc198>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6fQ_2SOADcz2"
      },
      "source": [
        "#### (b) Get an evaluation of the performance of your model on the test set using the built-in Keras function `evaluate`.  Is there evidence that your model has overfit the training data?  (See the solutions for lab 1 or ask if you're not sure what this means.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BP7UU0VX9Sw1",
        "outputId": "91617d28-8cd5-49d1-c145-5297e83c1c01",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        }
      },
      "source": [
        "print(my_model.evaluate(X_test, y_test))\n",
        "\n",
        "y_hat = my_model.predict(X_test)\n",
        "\n",
        "print(\"shape of y hat \" + str(y_hat.shape))\n",
        "print(\"shape of y test\" + str(y_test.shape))\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "ax.scatter(y_test, y_hat)\n",
        "ax.set_xlabel('Measured')\n",
        "ax.set_ylabel('Predicted')\n",
        "plt.show()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "586/586 [==============================] - 0s 50us/step\n",
            "36894693914.2116\n",
            "shape of y hat (586, 1)\n",
            "shape of y test(586, 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZcAAAEICAYAAACTVrmbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYmZmuXNwMTOz3Dm4mJlZ7hxczMwsd/8fnUW0irpjbWkAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i_lN7PFwWkxa",
        "colab_type": "text"
      },
      "source": [
        "It is 'overfitting' because the test evaluation is significantly more than the training mse. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "TW8QMx_RQFBn"
      },
      "source": [
        "#### (c) Find the test set performance of your model by manually obtaining the predicted values and computing the test set mean squared error based on them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ChYWP0y2QTI_",
        "outputId": "ec5cbe6d-b7bc-4604-b641-bab27f7f855b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 324
        }
      },
      "source": [
        "# Extract the w and b estimates\n",
        "(w, b) = my_model.layers[0].get_weights()\n",
        "b = b.reshape(b.shape[0], 1)\n",
        "print(\"b shape = \" + str(b.shape))\n",
        "print(\"w shape = \" + str(w.shape))\n",
        "print(\"X test shape\" + str(X_test.shape))\n",
        "\n",
        "print(\"y_test shape\" + str(y_test.shape))\n",
        "# Calculate a vector of z's\n",
        "z = b + np.dot(w.T, X_test.T) # replace None to the left with an actual calculation\n",
        "\n",
        "print(\"z\" + str(z.shape))\n",
        "\n",
        "# Calculate a vector of a's\n",
        "a = z # replace None to the left with an actual calculation\n",
        "\n",
        "print(\"a\" + str(a.shape))\n",
        "\n",
        "# Calculate and print the test set MSE\n",
        "MSE = np.mean(y_test - a^2)\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "b shape = (1, 1)\n",
            "w shape = (36, 1)\n",
            "X test shape(586, 36)\n",
            "y_test shape(586, 1)\n",
            "z(1, 586)\n",
            "a(1, 586)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-fba976d4c08c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# Calculate and print the test set MSE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mMSE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m^\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: ufunc 'bitwise_xor' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "hiN8hvUMaHO6"
      },
      "source": [
        "## Problem 2: Forest cover type prediction\n",
        "We have a data set from with characteristics of land in national forests; our goal is to predict the type of forest on that land.  There are 7 possible forest types: Spruce/Fir, Lodgepole Pine, Ponderosa Pine, Cottonwood/Willow, Aspen, Douglas-fir, or Krummholz.  Our features are things like elevation, slope of land, distance to water, soil type, and so on.  (Original data source: https://archive.ics.uci.edu/ml/datasets/Covertype)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VNp5PN3ubNcu",
        "outputId": "72ddd8b4-ab4c-4899-8cc7-2ad9652e7d0a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# read in data\n",
        "forest_cover = pd.read_csv(\"http://www.evanlray.com/data/UCIML/forest_cover/covtype.data\")\n",
        "\n",
        "# drop a couple of columns of all 0's\n",
        "to_drop = [20, 28]\n",
        "forest_cover.drop(forest_cover.columns[to_drop], axis = 1, inplace=True)\n",
        "\n",
        "# how much data do we have?\n",
        "print(\"shape of forest_cover = \" + str(forest_cover.shape))\n",
        "\n",
        "# perform a train/validation/test split\n",
        "# the indices of the split are the same as what was used in the original paper.\n",
        "# note that their test set is much larger than their train set, but you would\n",
        "# never do this in real life.\n",
        "train_slice = slice(0, 11340)\n",
        "val_slice = slice(11340, 11340+3780)\n",
        "test_slice = slice(11340+3780, 11340+3780+565892)\n",
        "\n",
        "X_train = forest_cover.iloc[train_slice, 0:52].to_numpy()\n",
        "y_train = forest_cover.iloc[train_slice, 52].to_numpy() - 1\n",
        "\n",
        "X_val = forest_cover.iloc[val_slice, 0:52].to_numpy()\n",
        "y_val = forest_cover.iloc[val_slice, 52].to_numpy() - 1\n",
        "\n",
        "X_test = forest_cover.iloc[test_slice, 0:52].to_numpy()\n",
        "y_test = forest_cover.iloc[test_slice, 52].to_numpy() - 1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "shape of forest_cover = (581011, 53)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "qob0HzpLrBKh"
      },
      "source": [
        "#### (a) In lab 1, I claimed that an essential preprocessing step for neural networks is to center and scale the inputs.  That isn't really necessary with just a multiple regression model like in problem 1, but it is necessary as soon as you start using sigmoid or softmax activations -- which you'll need in this problem.  Do the input normalization here.\n",
        "\n",
        "Note that you did this in lab 1, so you could just go find your old code there.  But you might like to try recreating it from scratch first.  (You want to eventually just know how to do things.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "h5_iOolnb8Yy",
        "outputId": "bbdcba80-8668-4de3-abad-184a960d2315",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "X_train_mean = np.mean(X_train, axis = 0) # add a call to np.mean here.  what will you use for the axis?\n",
        "X_train_std =  np.std(X_train, axis = 0)# add a call to np.std here.  what will you use for the axis?\n",
        "\n",
        "print(X_train.shape)\n",
        "print(X_train_mean.shape)\n",
        "print(X_train_std.shape)\n",
        "\n",
        "X_train = X_train - X_train_mean # add code here to subtract the column means from X_train.  How will broadcasting work?\n",
        "X_train = X_train/X_train_std# add code here to divide X_train by the column standard deviations.  How will broadcasting work?\n",
        "\n",
        "# normalize X_val, but using X_train_mean and X_train_std to do the normalization\n",
        "X_val = X_val - X_train_mean # add code here to subtract the column means from X_val\n",
        "X_val = X_val/X_train_std # add code here to divide X_val by the column standard deviations\n",
        "\n",
        "# normalize X_test, but using X_train_mean and X_train_std to do the normalization\n",
        "X_test = X_test - X_train_mean# add code here to subtract the column means from X_test\n",
        "X_test = X_test/X_train_std# add code here to divide X_test by the column standard deviations\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(11340, 52)\n",
            "(52,)\n",
            "(52,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ZC2-YMnQsarO"
      },
      "source": [
        "#### (b) Define an appropriate model in Keras.  Use stochastic gradient descent ('sgd') for your optimizer and 'accuracy' as an evaluation metric, and run the estimation process for 1000 epochs using a batch size equal to the number of examples in your training set.  We'll see what these things mean starting next week.\n",
        "Things to consider:\n",
        "\n",
        "* How many units do you need in your output layer?\n",
        "* What activation function do you want to use?\n",
        "* How many inputs (features) will your network use?\n",
        "* What is the appropriate loss function to use?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1JZjbKGte8Gj",
        "colab": {}
      },
      "source": [
        "treez = models.Sequential()\n",
        "\n",
        "treez.add(Dense(units = 3, activation = \"relu\", input_shape = (52, )))\n",
        "treez.add(Dense(units = 7, activation = \"softmax\", input_shape = (52,)))\n",
        "\n",
        "treez.compile(optimizer = 'sgd', loss = \"categorical_crossentropy h\", metrics = 'accuracy')\n",
        "\n",
        "\n",
        "treez.fit(X_train, y_train,\n",
        "  validation_data = (X_val, y_val),\n",
        "  epochs = 11340, batch_size = 1875)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "nl_1PJeVtnYQ"
      },
      "source": [
        "#### (c) Get an evaluation of the performance of your model on the test set using the built-in Keras function `evaluate`.  Is there evidence that your model has overfit the training data?  (See the solutions for lab 1 or ask me if you're not sure what this means.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "EXsuIGyCcOM5",
        "colab": {}
      },
      "source": [
        "print(my_model.evaluate(X_test, y_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "tFwZyVntukRF"
      },
      "source": [
        "#### (d) Write your own version of the softmax function according to the docstring in the starter function below.\n",
        "Note that this function expects each observation to be represented in a column of the matrix `z`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KWaImUCSwiZO",
        "colab": {}
      },
      "source": [
        "def my_softmax(z):\n",
        "  '''\n",
        "  Calculate softmax(z) where z is a K by m matrix\n",
        "  \n",
        "  Arguments:\n",
        "   - z, a K by m matrix: the entry in row j and column i of z contains \n",
        "     b_j + w_j^T x^(i), the linear combination of input features for class j and\n",
        "     observation m (we're assuming this computation has already been done for us)\n",
        "  \n",
        "  Return:\n",
        "   - a K by M matrix where column m is calculated as softmax of column m of z\n",
        "  '''\n",
        "  return softmax(z)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "8zn7cK0RxVsN"
      },
      "source": [
        "If you want, you can test your function above out with the following code to make sure it seems to be working (all entries of the result should be non-negative, and the columns should add up to 1):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dyhSNivSxeIO",
        "colab": {}
      },
      "source": [
        "z = np.array([[17, 5, 2, 7],\n",
        "              [5, 5, 1, 2],\n",
        "              [2, 2, 6, -10]])\n",
        "my_softmax(z)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "jwgj29GFt0B9"
      },
      "source": [
        "#### (e) Find the test set performance of your model by manually obtaining the predicted values."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "PvTSOP4ToqUO"
      },
      "source": [
        "At some point, you will need to use the softmax function.  Although you wrote your own softmax function above, you should instead use the softmax function from the scipy package that was imported above.  Its implementation is more numerically stable; I'll talk more about this some time later.\n",
        "\n",
        "To find the class with the highest probability based on your `a` array, check out the [argmax](https://docs.scipy.org/doc/numpy/reference/generated/numpy.argmax.html) function in numpy.  This function will find the index of the largest entry along a given `axis` in a vector."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3vlQy-69kKbQ",
        "colab": {}
      },
      "source": [
        "# The next two lines extract the estimated weights w and bias b from the model\n",
        "# fit and then reshape b to be a 7 by 1 matrix.\n",
        "(w, b) = multi_logistic_model.layers[0].get_weights()\n",
        "b = b.reshape(b.shape[0], 1)\n",
        "\n",
        "# Calculate the vector z here:\n",
        "# This should involve b, X_test, and w.  Use np.dot() and broadcasting.\n",
        "# Do you need to find any transposes?\n",
        "z = \n",
        "\n",
        "# Calculate the activation a:\n",
        "# Use the softmax function.  The softmax function takes an axis argument.\n",
        "# The axis to use depends on how you set up your calculation for z.\n",
        "a =  # use softmax here\n",
        "\n",
        "# Find the predicted value y hat for each observation\n",
        "y_hat =  # use np.argmax here\n",
        "\n",
        "# For each prediction, determine whether the prediction was correct by\n",
        "# comparing it to the observed test set response.  The result of this\n",
        "# calculation should be a logical vector of the same shape as y_test\n",
        "# that is True for cases where the test set prediction was correct and False\n",
        "# for test set cases where the prediction was wrong.\n",
        "# Careful!  Make sure y_hat and y_test have the same shape before comparing\n",
        "# them, or else you'll accidentally broadcast the comparison and be confused...\n",
        "y_hat_correct_lgl = \n",
        "\n",
        "# Determine what proportion of your test set predictions were correct by\n",
        "# calculating the *mean* of the values in the y_hat_correct_lgl variable.\n",
        "# Note that any True values (correct predictions) are converted to 1 and False\n",
        "# values are converted to 0 when you do this calculation.\n",
        "proportion_correct = \n",
        "\n",
        "# Print the proportion correct so you can see it after running this code cell\n",
        "print(\"Proportion correct = \" + str(proportion_correct))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}